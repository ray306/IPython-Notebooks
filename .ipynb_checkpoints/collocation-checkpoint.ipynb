{
 "metadata": {
  "name": "",
  "signature": "sha256:fd901f1d91b9c2fe60fd852549830e7446504dc81767e98019bede8c15f154ae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "from collections import Counter\n",
      "import os\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "path = 'D:\\\\nlp\\\\en\\\\COCA\\\\COCA_sample_lineartext\\\\'\n",
      "documents = []\n",
      "for filename in os.listdir(path+'result\\\\'):\n",
      "    with open(path+'result\\\\'+filename) as f:\n",
      "        documents += f.read().split('\\n')\n",
      "\n",
      "# remove common words and tokenize\n",
      "stopwords = set(stopwords.raw('english').split()) ## \u83b7\u53d6\u82f1\u6587\u505c\u7528\u8bcd\u8868\n",
      "texts = [[word for word in document.split() if word not in stopwords]\n",
      "         for document in documents]\n",
      "\n",
      "# remove words that appear only once\n",
      "\n",
      "all_tokens = [word for text in texts for word in text]\n",
      "fd = Counter(all_tokens)\n",
      "tokens_once = set(word for word in fd if fd[word] == 1)\n",
      "texts = [[word for word in text if word not in tokens_once]\n",
      "         for text in texts]\n",
      "\n",
      "tokens = set(word for word in fd if fd[word] > 1)\n",
      "cfd_win = {}\n",
      "cfd_sent = {}\n",
      "pmi_win = {}\n",
      "pmi_sent ={}\n",
      "for i in tokens:\n",
      "    cfd_win[i] = Counter()\n",
      "    cfd_sent[i] = Counter()\n",
      "    pmi_win[i] = {}\n",
      "    pmi_sent[i] = {}\n",
      "\n",
      "for sent in texts:\n",
      "    for (index,token) in enumerate(sent):\n",
      "        if index > 4:\n",
      "            window = sent[index-5:index+5]   ## \u524d\u540e5\u4e2a\u5355\u8bcd,\u7a97\u53e3\n",
      "        else:\n",
      "            window = sent[0:index+5]         ## \u524d\u540e5\u4e2a\u5355\u8bcd,\u7a97\u53e3\n",
      "        cfd_win[token].update(window)       ## \u589e\u52a0\u5165\u5f53\u524d\u5355\u8bcd\u7684\u76f8\u5173\u5355\u8bcd\n",
      "        cfd_sent[token].update(sent)\n",
      "\n",
      "import math\n",
      "pmi_sent ={}\n",
      "pmi_win = {}\n",
      "for i in tokens:\n",
      "    pmi_sent[i] = {}\n",
      "    pmi_win[i] = {}\n",
      "\n",
      "wordsCount = sum([len(text) for text in texts])\n",
      "for t1 in cfd_win:\n",
      "    for t2 in cfd_win[t1]:\n",
      "        cfd = float(cfd_win[t1][t2]+cfd_win[t2][t1])/2.0\n",
      "        pmi_win[t1][t2] = cfd/len(tokens)*math.log(cfd*len(tokens)/(fd[t1]*fd[t2]),2)\n",
      "for t1 in cfd_sent:\n",
      "    for t2 in cfd_sent[t1]:\n",
      "        pmi_sent[t1][t2] =math.log(float(cfd_sent[t1][t2])*len(tokens)/(fd[t1]*fd[t2]),2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "pmi_sent ={}\n",
      "for i in tokens:\n",
      "    pmi_sent[i] = {}\n",
      "\n",
      "wordsCount = sum([len(text) for text in texts])\n",
      "# for t1 in cfd_win:\n",
      "#     for t2 in cfd_win[t1]:\n",
      "#         cfd = float(cfd_win[t1][t2]+cfd_win[t2][t1])/2.0\n",
      "#         pmi_win[t1][t2] = cfd/len(tokens)*math.log(cfd*len(tokens)/(fd[t1]*fd[t2]),2)\n",
      "for t1 in cfd_sent:\n",
      "    for t2 in cfd_sent[t1]:\n",
      "        pmi_sent[t1][t2] =math.log(float(cfd_sent[t1][t2])*len(tokens)/(fd[t1]*fd[t2]),2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 0.5\n",
      "pmi_sent_filtered = {}\n",
      "for i in pmi_sent:\n",
      "    pmi_sent_filtered[i] = [(k,v) for (k, v) in pmi_sent[i].iteritems() if v > threshold]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target='rain'\n",
      "\n",
      "re = Counter()\n",
      "for (token1,pmi1) in pmi_sent_filtered[target]:\n",
      "    for (token2,pmi2) in pmi_sent_filtered[token1]:\n",
      "        re.update({token2:pmi1*pmi2})\n",
      "\n",
      "re.most_common(50)\n",
      "#re.most_common(len(filter(lambda v:v>50, re.values())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[('scapegoat', 94.7669836484094),\n",
        " ('overhang', 94.7669836484094),\n",
        " ('lebanese', 94.7669836484094),\n",
        " ('lashing', 94.7669836484094),\n",
        " ('tyndale', 87.92947700617427),\n",
        " ('monthlong', 87.92947700617427),\n",
        " ('reaping', 87.92947700617427),\n",
        " ('defamation', 87.92947700617427),\n",
        " ('pinnacle', 87.92947700617427),\n",
        " ('whirlwind', 83.92979202203492),\n",
        " ('abbey', 83.92979202203492),\n",
        " ('anti', 83.92979202203492),\n",
        " ('oddest', 83.92979202203492),\n",
        " ('zap', 83.92979202203492),\n",
        " ('surpass', 83.92979202203492),\n",
        " ('mathletes', 83.00197297048771),\n",
        " ('butenko', 83.00197297048771),\n",
        " ('lingering', 82.59122459496582),\n",
        " ('nonsensical', 81.09197036393915),\n",
        " ('clickclickclickclick', 81.09197036393915),\n",
        " ('naral', 81.09197036393915),\n",
        " ('tessa', 81.09197036393915),\n",
        " ('torrential', 81.09197036393915),\n",
        " ('guerrero', 79.34446911359828),\n",
        " ('ointment', 78.89078487682474),\n",
        " ('hand-held', 78.89078487682474),\n",
        " ('pavilion', 78.89078487682474),\n",
        " ('knack', 78.89078487682474),\n",
        " ('alberto', 77.0922853797998),\n",
        " ('darken', 76.74942882897376),\n",
        " ('interwoven', 76.74942882897376),\n",
        " ('drawknife', 76.74942882897376),\n",
        " ('baptism', 75.5716757217291),\n",
        " ('gearing', 75.5716757217291),\n",
        " ('assailant', 75.5716757217291),\n",
        " ('raleigh', 75.5716757217291),\n",
        " ('bleacher', 75.0696025509107),\n",
        " ('sphinx', 75.0696025509107),\n",
        " ('pelted', 75.0696025509107),\n",
        " ('streetlight', 74.25446372170406),\n",
        " ('rallying', 73.09260039566043),\n",
        " ('hezbollah', 73.09260039566043),\n",
        " ('arses', 73.09260039566043),\n",
        " ('grounder', 73.09192497208434),\n",
        " ('conceptualized', 73.09192497208434),\n",
        " ('renew', 72.05327823458963),\n",
        " ('peta', 72.05327823458963),\n",
        " ('soderquist', 71.6548800674925),\n",
        " ('trehub', 71.6548800674925),\n",
        " ('lazily', 71.36502666541458)]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target='cloud'\n",
      "re = Counter()\n",
      "for (token1,pmi1) in pmi_sent_filtered[target]:\n",
      "    for (token2,pmi2) in pmi_sent_filtered[token1]:\n",
      "        tPMI = pmi1*pmi2\n",
      "        for (token3,pmi3) in pmi_sent_filtered[token2]:\n",
      "            re.update({token3:tPMI*pmi3})\n",
      "re.most_common(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[('cloud', 823286.7531774156),\n",
        " ('heavy', 590736.4487229477),\n",
        " ('thick', 560368.5778587605),\n",
        " ('sun', 553362.0633129633),\n",
        " ('sky', 549220.4301432852),\n",
        " ('sea', 548954.8820774246),\n",
        " ('black', 531582.5496485491),\n",
        " ('sidebar', 524645.7031806031),\n",
        " ('blue', 512264.6621142789),\n",
        " ('water', 509219.851778929),\n",
        " ('rain', 494191.85051255487),\n",
        " ('dark', 481054.86538983474),\n",
        " ('white', 474867.1074960625),\n",
        " ('wind', 472499.05884168437),\n",
        " ('red', 463839.3927381616),\n",
        " ('tree', 462458.74499922426),\n",
        " ('freshwater', 459965.4733969142),\n",
        " ('von', 458986.5190781293),\n",
        " ('fresh', 454612.32329258526),\n",
        " ('thin', 451802.34021572524),\n",
        " ('onto', 450577.115873264),\n",
        " ('skin', 450119.47614631086),\n",
        " ('island', 449312.85108077404),\n",
        " ('beneath', 446356.51799953973),\n",
        " ('ground', 443139.8807538918),\n",
        " ('maestro', 441004.58327079524),\n",
        " ('river', 439770.9447585974),\n",
        " ('glass', 439616.83688129304),\n",
        " ('peak', 437327.46219411166),\n",
        " ('surface', 436557.044491153),\n",
        " ('large', 434190.25138656073),\n",
        " ('stone', 428922.6918490912),\n",
        " ('air', 427919.73898609175),\n",
        " ('wet', 426544.1321021999),\n",
        " ('rock', 426431.40071886824),\n",
        " ('photo', 420958.8040288288),\n",
        " ('mile', 420730.1758774553),\n",
        " ('leaf', 417659.34870123735),\n",
        " ('hot', 417587.050897114),\n",
        " ('whose', 417513.7704926949),\n",
        " ('valley', 416486.48209949984),\n",
        " ('soft', 415486.7783773544),\n",
        " ('small', 414553.3667537289),\n",
        " ('august', 413670.54033748974),\n",
        " ('mysterious', 412551.9012138765),\n",
        " ('forest', 409272.6548562617),\n",
        " ('wilderness', 408035.76150092855),\n",
        " ('fire', 406672.98312244547),\n",
        " ('oil', 405826.7945178854),\n",
        " ('golden', 405418.6187846902)]"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "pd.DataFrame(re,index=re.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = \"I do not like green eggs and ham, I do not \\\"like\\\" them Sam I am!\"\n",
      "tokens = nltk.wordpunct_tokenize(text)\n",
      "print nltk.FreqDist(nltk.bigrams(tokens))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<FreqDist: ('I', 'do'): 2, ('do', 'not'): 2, ('\"', 'like'): 1, ('\"', 'them'): 1, (',', 'I'): 1, ('I', 'am'): 1, ('Sam', 'I'): 1, ('am', '!'): 1, ('and', 'ham'): 1, ('eggs', 'and'): 1, ...>\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.metrics.spearman import *\n",
      "spearman_correlation(pmi_sent['se'],pmi_sent['handbook'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "0.9775185352641972"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.collocations import *\n",
      "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
      "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
      "finder = BigramCollocationFinder.from_words('121212341')\n",
      "print finder.nbest(bigram_measures.pmi, 10)  \n",
      "finder.apply_freq_filter(3)\n",
      "print finder.nbest(bigram_measures.pmi, 10)\n",
      "finder = BigramCollocationFinder.from_words('12121234',window_size = 3)\n",
      "print finder.nbest(bigram_measures.pmi, 10)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[('3', '4'), ('2', '3'), ('1', '2'), ('4', '1'), ('2', '1')]"
       ]
      }
     ],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}