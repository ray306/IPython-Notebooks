{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "# read all documents in one variant\n",
    "path = 'f:\\\\nlp\\\\en\\\\COCA\\\\COCA_sample_lineartext\\\\'\n",
    "documents = []\n",
    "for filename in os.listdir(path+'result\\\\'):\n",
    "    with open(path+'result\\\\'+filename) as f:\n",
    "        documents += f.read().split('\\n')\n",
    "\n",
    "texts_raw = [[word for word in document.split() ]\n",
    "         for document in documents]\n",
    "tokens_all = [word for text in texts_raw for word in text]\n",
    "\n",
    "frequency = []\n",
    "dict_w2n = dict()\n",
    "dict_n2w = []\n",
    "\n",
    "freq = Counter(tokens_all)\n",
    "idx = 0\n",
    "for i in freq.most_common(1000000000):\n",
    "    word = i[0]\n",
    "    count = i[1]\n",
    "    dict_n2w.append(word)\n",
    "    dict_w2n[word] = idx\n",
    "    idx+=1\n",
    "    frequency.append(count) \n",
    "\n",
    "#remove the words appear only one time\n",
    "tokens_once = set(word for word in freq if freq[word] == 1)\n",
    "tokens_cleaned = set(word for word in freq if freq[word] > 1)\n",
    "texts_cleaned = [[word for word in text if word not in tokens_once]\n",
    "         for text in texts_raw]\n",
    "\n",
    "# transform words to numbers\n",
    "texts_cleaned_transformed = [[dict_w2n[w] for w in text]\n",
    "         for text in texts_cleaned]\n",
    "\n",
    "# get th dictionary\n",
    "dict_cleaned = set(word for word in freq if freq[word] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all documents in one variant\n",
    "documents = []\n",
    "raw = np.loadtxt('F:\\nlp\\en\\ngram\\w5_.txt',head=None,sep=' ')\n",
    "\n",
    "\n",
    "texts_raw = [[word for word in document.split() ]\n",
    "         for document in documents]\n",
    "tokens_all = [word for text in texts_raw for word in text]\n",
    "\n",
    "frequency = []\n",
    "dict_w2n = dict()\n",
    "dict_n2w = []\n",
    "\n",
    "freq = Counter(tokens_all)\n",
    "idx = 0\n",
    "for i in freq.most_common(1000000000):\n",
    "    word = i[0]\n",
    "    count = i[1]\n",
    "    dict_n2w.append(word)\n",
    "    dict_w2n[word] = idx\n",
    "    idx+=1\n",
    "    frequency.append(count) \n",
    "\n",
    "#remove the words appear only one time\n",
    "tokens_once = set(word for word in freq if freq[word] == 1)\n",
    "tokens_cleaned = set(word for word in freq if freq[word] > 1)\n",
    "texts_cleaned = [[word for word in text if word not in tokens_once]\n",
    "         for text in texts_raw]\n",
    "\n",
    "# transform words to numbers\n",
    "texts_cleaned_transformed = [[dict_w2n[w] for w in text]\n",
    "         for text in texts_cleaned]\n",
    "\n",
    "# get th dictionary\n",
    "dict_cleaned = set(word for word in freq if freq[word] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read all documents in one variant\n",
    "documents = []\n",
    "raw = np.loadtxt('F:\\\\nlp\\\\en\\\\ngram\\\\test.txt',delimiter='\\t',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"b'16'\", \"b'6'\", \"b'9'\", \"b'6'\", \"b'6'\", \"b'8'\", \"b'28'\", \"b'6'\",\n",
       "       \"b'11'\", \"b'12'\", \"b'13'\", \"b'12'\", \"b'42'\", \"b'16'\", \"b'25'\",\n",
       "       \"b'9'\", \"b'14'\", \"b'30'\", \"b'10'\"], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "freq = Counter(raw[:,1:].flatten())\n",
    "tokens = set(raw[:,1:].flatten())\n",
    "\n",
    "frequency = []\n",
    "dict_w2n = dict()\n",
    "dict_n2w = []\n",
    "\n",
    "frequency = []\n",
    "idx = 0\n",
    "for i in freq.most_common(1000000000):\n",
    "    word = i[0]\n",
    "    count = i[1]\n",
    "    dict_n2w.append(word)\n",
    "    dict_w2n[word] = idx\n",
    "    idx+=1\n",
    "    frequency.append(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in raw:\n",
    "    for (index,token) in enumerate(window[1:]):\n",
    "        sub_window = window[1+index:]         ## 前后5个单词,窗口\n",
    "        cooccur_CFD[token].update(np.repeat(sub_window,window[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 6, 2: 6, 3: 6})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.update(np.repeat([1,2,3],3))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DictInit(keys,value):\n",
    "    Dict = {}\n",
    "    for k in keys:\n",
    "        t = Counter()\n",
    "        Dict[k] = t\n",
    "    return Dict\n",
    "\n",
    "cooccur_CFD = DictInit(range(len(tokens_cleaned)),Counter())\n",
    "\n",
    "for sent in texts_cleaned_transformed:\n",
    "    for (index,token) in enumerate(sent):\n",
    "        window = sent[index:index+5]         ## 前后5个单词,窗口\n",
    "        cooccur_CFD[token].update(window)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "count = len(tokens_cleaned)\n",
    "cooccur = np.zeros((count,count), dtype=np.uint32)\n",
    "\n",
    "for w1,co_words in cooccur_CFD.items():\n",
    "    for w2,count in co_words.items():\n",
    "        cooccur[w1,w2] += count\n",
    "        cooccur[w2,w1] += count\n",
    "        \n",
    "del cooccur_CFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cooccur = np.matrix(cooccur,float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-f040a1bd0d7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcooccur_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcooccur\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcooccur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# np.matrix([[1,2],[3,4]])/np.matrix([[1,2],[3,4]]).sum(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  \\subsequent w1 w2\n",
    "# prior   ---------\n",
    "# w1     | \n",
    "# w2     |\n",
    "\n",
    "cooccur_cond = cooccur/cooccur.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx,i in enumerate(cooccur[2281,:]/cooccur.sum(0)):\n",
    "    if i!=0:\n",
    "        res.append((dict_n2w[idx],i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = np.array(res)\n",
    "res[res[:,1].argsort(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2268, 1388, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_w2n['cloud'],dict_w2n['rain'],cooccur[2268, 1388]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2281"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_w2n['cloud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "co_1 = cooccur[2281,:] * cooccur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "file = h5py.File('d:/cooccur.h5','w')\n",
    "file.create_dataset('cooccur', data = cooccur)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "a=csr_matrix((10,10), dtype=np.int8)\n",
    "b=dok_matrix((10,10), dtype=np.int8)\n",
    "c=lil_matrix((10,10), dtype=np.int8)\n",
    "d=csc_matrix((10,10), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 111 µs per loop\n",
      "1000 loops, best of 3: 304 µs per loop\n",
      "1000 loops, best of 3: 262 µs per loop\n",
      "10000 loops, best of 3: 110 µs per loop\n",
      "1000 loops, best of 3: 1.86 ms per loop\n",
      "1000 loops, best of 3: 434 µs per loop\n",
      "1000 loops, best of 3: 1.52 ms per loop\n",
      "1000 loops, best of 3: 1.71 ms per loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%timeit a/div\n",
    "%timeit b/div\n",
    "%timeit c/div\n",
    "%timeit d/div\n",
    "%timeit np.divide(a,div)\n",
    "%timeit np.divide(b,div)\n",
    "%timeit np.divide(c,div)\n",
    "%timeit np.divide(d,div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div=csr_matrix(np.matrix([1,2,3,4,5,6,7,8,9,10]))\n",
    "type(div.dot(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 198 µs per loop\n",
      "1000 loops, best of 3: 547 µs per loop\n",
      "1000 loops, best of 3: 457 µs per loop\n"
     ]
    }
   ],
   "source": [
    "a=csr_matrix((4, 4), dtype=np.float32)\n",
    "b=dok_matrix((4, 4), dtype=np.float32)\n",
    "c=lil_matrix((4, 4), dtype=np.float32)\n",
    "%timeit a.dot(a)\n",
    "%timeit b.dot(b)\n",
    "%timeit c.dot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.38629436,  2.19722458])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "t=np.array([1,4,9])\n",
    "np.array([math.log(x) for x in t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooccur_p = cooccur/np.matrix(frequency)\n",
    "\n",
    "target = word_w2n['数学']\n",
    "\n",
    "n_order = [cooccur_p[target]]\n",
    "n_order.append(n_order[-1].dot(cooccur_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[12, 15, 18]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix([1,1,1]).dot(np.matrix([[1,2,3],[4,5,6],[7,8,9]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
