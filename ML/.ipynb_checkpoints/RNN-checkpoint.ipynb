{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n",
      "00001\t#include <Python.h>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "===============================\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00002\t#include <iostream>\n",
      "00003\t#include <math.h>\n",
      "00004\t#include <numpy/arrayobject.h>\n",
      "00005\t#include <numpy/arrayscalars.h>\n",
      "00006\t#include <vector>\n",
      "00007\t#include <algorithm>\n",
      "00008\t//////////////////////\n",
      "00009\t////  Support Code\n",
      "00010\t//////////////////////\n",
      "00011\t\n",
      "00012\t\n",
      "00013\t    namespace {\n",
      "00014\t    struct __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673 {\n",
      "00015\t        PyObject* __ERROR;\n",
      "00016\t\n",
      "00017\t        PyObject* storage_V3;\n",
      "00018\tPyObject* storage_V5;\n",
      "00019\tPyObject* storage_V7;\n",
      "00020\tPyObject* storage_V1;\n",
      "00021\t        \n",
      "00022\t\n",
      "00023\t        __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673() {}\n",
      "00024\t        ~__struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673(void) {\n",
      "00025\t            cleanup();\n",
      "00026\t        }\n",
      "00027\t\n",
      "00028\t        int init(PyObject* __ERROR, PyObject* storage_V3, PyObject* storage_V5, PyObject* storage_V7, PyObject* storage_V1) {\n",
      "00029\t            Py_XINCREF(storage_V3);\n",
      "00030\tPy_XINCREF(storage_V5);\n",
      "00031\tPy_XINCREF(storage_V7);\n",
      "00032\tPy_XINCREF(storage_V1);\n",
      "00033\t            this->storage_V3 = storage_V3;\n",
      "00034\tthis->storage_V5 = storage_V5;\n",
      "00035\tthis->storage_V7 = storage_V7;\n",
      "00036\tthis->storage_V1 = storage_V1;\n",
      "00037\t            \n",
      "00038\t\n",
      "00039\t\n",
      "00040\t\n",
      "00041\t\n",
      "00042\t\n",
      "00043\t            this->__ERROR = __ERROR;\n",
      "00044\t            return 0;\n",
      "00045\t        }\n",
      "00046\t        void cleanup(void) {\n",
      "00047\t            __label_1:\n",
      "00048\t\n",
      "00049\tdouble __DUMMY_1;\n",
      "00050\t__label_3:\n",
      "00051\t\n",
      "00052\tdouble __DUMMY_3;\n",
      "00053\t__label_5:\n",
      "00054\t\n",
      "00055\tdouble __DUMMY_5;\n",
      "00056\t__label_7:\n",
      "00057\t\n",
      "00058\tdouble __DUMMY_7;\n",
      "00059\t__label_10:\n",
      "00060\t\n",
      "00061\tdouble __DUMMY_10;\n",
      "00062\t\n",
      "00063\t            Py_XDECREF(this->storage_V3);\n",
      "00064\tPy_XDECREF(this->storage_V5);\n",
      "00065\tPy_XDECREF(this->storage_V7);\n",
      "00066\tPy_XDECREF(this->storage_V1);\n",
      "00067\t        }\n",
      "00068\t        int run(void) {\n",
      "00069\t            int __failure = 0;\n",
      "00070\t            \n",
      "00071\t    PyObject* py_V1;\n",
      "00072\t    \n",
      "00073\t        PyArrayObject* V1;\n",
      "00074\t        \n",
      "00075\t            typedef npy_float64 dtype_V1;\n",
      "00076\t            \n",
      "00077\t    PyObject* py_V3;\n",
      "00078\t    \n",
      "00079\t        PyArrayObject* V3;\n",
      "00080\t        \n",
      "00081\t            typedef npy_float64 dtype_V3;\n",
      "00082\t            \n",
      "00083\t    PyObject* py_V5;\n",
      "00084\t    \n",
      "00085\t        PyArrayObject* V5;\n",
      "00086\t        \n",
      "00087\t            typedef npy_float64 dtype_V5;\n",
      "00088\t            \n",
      "00089\t    PyObject* py_V7;\n",
      "00090\t    \n",
      "00091\t        PyArrayObject* V7;\n",
      "00092\t        \n",
      "00093\t            typedef npy_float64 dtype_V7;\n",
      "00094\t            \n",
      "00095\t{\n",
      "00096\t\n",
      "00097\t    py_V1 = PyList_GET_ITEM(storage_V1, 0);\n",
      "00098\t    {Py_XINCREF(py_V1);}\n",
      "00099\t    \n",
      "00100\t        if (py_V1 == Py_None)\n",
      "00101\t        {\n",
      "00102\t            \n",
      "00103\t        V1 = NULL;\n",
      "00104\t        \n",
      "00105\t        }\n",
      "00106\t        else\n",
      "00107\t        {\n",
      "00108\t            \n",
      "00109\t            V1 = NULL;\n",
      "00110\t            if (py_V1 == Py_None) {\n",
      "00111\t                // We can either fail here or set V1 to NULL and rely on Ops\n",
      "00112\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00113\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00114\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00115\t                {\n",
      "00116\t        __failure = 2;\n",
      "00117\t        if (!PyErr_Occurred()) {\n",
      "00118\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00119\t                \"Unexpected error in an Op's C code. \"\n",
      "00120\t                \"No Python exception was set.\");\n",
      "00121\t            }\n",
      "00122\t        goto __label_2;}\n",
      "00123\t            }\n",
      "00124\t            if (!PyArray_Check(py_V1)) {\n",
      "00125\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00126\t                {\n",
      "00127\t        __failure = 2;\n",
      "00128\t        if (!PyErr_Occurred()) {\n",
      "00129\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00130\t                \"Unexpected error in an Op's C code. \"\n",
      "00131\t                \"No Python exception was set.\");\n",
      "00132\t            }\n",
      "00133\t        goto __label_2;}\n",
      "00134\t            }\n",
      "00135\t            // We expect NPY_FLOAT64\n",
      "00136\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V1)) {\n",
      "00137\t                PyArrayObject * tmp = (PyArrayObject*) py_V1;\n",
      "00138\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00139\t                             \"expected an aligned array of type %ld \"\n",
      "00140\t                             \"(NPY_FLOAT64), got non-aligned array of type %ld\"\n",
      "00141\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00142\t                             \"%ld, %ld, %ld\"\n",
      "00143\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00144\t                             (long int) NPY_FLOAT64,\n",
      "00145\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V1),\n",
      "00146\t                             (long int) PyArray_NDIM(tmp),\n",
      "00147\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00148\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00149\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00150\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00151\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00152\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00153\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00154\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00155\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00156\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00157\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00158\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00159\t            );\n",
      "00160\t                {\n",
      "00161\t        __failure = 2;\n",
      "00162\t        if (!PyErr_Occurred()) {\n",
      "00163\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00164\t                \"Unexpected error in an Op's C code. \"\n",
      "00165\t                \"No Python exception was set.\");\n",
      "00166\t            }\n",
      "00167\t        goto __label_2;}\n",
      "00168\t            }\n",
      "00169\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00170\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00171\t            if (PyArray_TYPE((PyArrayObject*) py_V1) != NPY_FLOAT64) {\n",
      "00172\t                PyErr_Format(PyExc_TypeError,\n",
      "00173\t                             \"expected type_num %d (NPY_FLOAT64) got %d\",\n",
      "00174\t                             NPY_FLOAT64, PyArray_TYPE((PyArrayObject*) py_V1));\n",
      "00175\t                {\n",
      "00176\t        __failure = 2;\n",
      "00177\t        if (!PyErr_Occurred()) {\n",
      "00178\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00179\t                \"Unexpected error in an Op's C code. \"\n",
      "00180\t                \"No Python exception was set.\");\n",
      "00181\t            }\n",
      "00182\t        goto __label_2;}\n",
      "00183\t            }\n",
      "00184\t            \n",
      "00185\t        V1 = (PyArrayObject*)(py_V1);\n",
      "00186\t        Py_XINCREF(V1);\n",
      "00187\t        \n",
      "00188\t        }\n",
      "00189\t        \n",
      "00190\t{\n",
      "00191\t\n",
      "00192\t    py_V3 = PyList_GET_ITEM(storage_V3, 0);\n",
      "00193\t    {Py_XINCREF(py_V3);}\n",
      "00194\t    \n",
      "00195\t            V3 = NULL;\n",
      "00196\t            if (py_V3 == Py_None) {\n",
      "00197\t                // We can either fail here or set V3 to NULL and rely on Ops\n",
      "00198\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00199\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00200\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00201\t                {\n",
      "00202\t        __failure = 4;\n",
      "00203\t        if (!PyErr_Occurred()) {\n",
      "00204\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00205\t                \"Unexpected error in an Op's C code. \"\n",
      "00206\t                \"No Python exception was set.\");\n",
      "00207\t            }\n",
      "00208\t        goto __label_4;}\n",
      "00209\t            }\n",
      "00210\t            if (!PyArray_Check(py_V3)) {\n",
      "00211\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00212\t                {\n",
      "00213\t        __failure = 4;\n",
      "00214\t        if (!PyErr_Occurred()) {\n",
      "00215\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00216\t                \"Unexpected error in an Op's C code. \"\n",
      "00217\t                \"No Python exception was set.\");\n",
      "00218\t            }\n",
      "00219\t        goto __label_4;}\n",
      "00220\t            }\n",
      "00221\t            // We expect NPY_FLOAT64\n",
      "00222\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V3)) {\n",
      "00223\t                PyArrayObject * tmp = (PyArrayObject*) py_V3;\n",
      "00224\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00225\t                             \"expected an aligned array of type %ld \"\n",
      "00226\t                             \"(NPY_FLOAT64), got non-aligned array of type %ld\"\n",
      "00227\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00228\t                             \"%ld, %ld, %ld\"\n",
      "00229\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00230\t                             (long int) NPY_FLOAT64,\n",
      "00231\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V3),\n",
      "00232\t                             (long int) PyArray_NDIM(tmp),\n",
      "00233\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00234\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00235\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00236\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00237\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00238\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00239\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00240\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00241\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00242\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00243\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00244\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00245\t            );\n",
      "00246\t                {\n",
      "00247\t        __failure = 4;\n",
      "00248\t        if (!PyErr_Occurred()) {\n",
      "00249\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00250\t                \"Unexpected error in an Op's C code. \"\n",
      "00251\t                \"No Python exception was set.\");\n",
      "00252\t            }\n",
      "00253\t        goto __label_4;}\n",
      "00254\t            }\n",
      "00255\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00256\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00257\t            if (PyArray_TYPE((PyArrayObject*) py_V3) != NPY_FLOAT64) {\n",
      "00258\t                PyErr_Format(PyExc_TypeError,\n",
      "00259\t                             \"expected type_num %d (NPY_FLOAT64) got %d\",\n",
      "00260\t                             NPY_FLOAT64, PyArray_TYPE((PyArrayObject*) py_V3));\n",
      "00261\t                {\n",
      "00262\t        __failure = 4;\n",
      "00263\t        if (!PyErr_Occurred()) {\n",
      "00264\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00265\t                \"Unexpected error in an Op's C code. \"\n",
      "00266\t                \"No Python exception was set.\");\n",
      "00267\t            }\n",
      "00268\t        goto __label_4;}\n",
      "00269\t            }\n",
      "00270\t            \n",
      "00271\t        V3 = (PyArrayObject*)(py_V3);\n",
      "00272\t        Py_XINCREF(V3);\n",
      "00273\t        \n",
      "00274\t{\n",
      "00275\t\n",
      "00276\t    py_V5 = PyList_GET_ITEM(storage_V5, 0);\n",
      "00277\t    {Py_XINCREF(py_V5);}\n",
      "00278\t    \n",
      "00279\t            V5 = NULL;\n",
      "00280\t            if (py_V5 == Py_None) {\n",
      "00281\t                // We can either fail here or set V5 to NULL and rely on Ops\n",
      "00282\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00283\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00284\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00285\t                {\n",
      "00286\t        __failure = 6;\n",
      "00287\t        if (!PyErr_Occurred()) {\n",
      "00288\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00289\t                \"Unexpected error in an Op's C code. \"\n",
      "00290\t                \"No Python exception was set.\");\n",
      "00291\t            }\n",
      "00292\t        goto __label_6;}\n",
      "00293\t            }\n",
      "00294\t            if (!PyArray_Check(py_V5)) {\n",
      "00295\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00296\t                {\n",
      "00297\t        __failure = 6;\n",
      "00298\t        if (!PyErr_Occurred()) {\n",
      "00299\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00300\t                \"Unexpected error in an Op's C code. \"\n",
      "00301\t                \"No Python exception was set.\");\n",
      "00302\t            }\n",
      "00303\t        goto __label_6;}\n",
      "00304\t            }\n",
      "00305\t            // We expect NPY_FLOAT64\n",
      "00306\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V5)) {\n",
      "00307\t                PyArrayObject * tmp = (PyArrayObject*) py_V5;\n",
      "00308\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00309\t                             \"expected an aligned array of type %ld \"\n",
      "00310\t                             \"(NPY_FLOAT64), got non-aligned array of type %ld\"\n",
      "00311\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00312\t                             \"%ld, %ld, %ld\"\n",
      "00313\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00314\t                             (long int) NPY_FLOAT64,\n",
      "00315\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V5),\n",
      "00316\t                             (long int) PyArray_NDIM(tmp),\n",
      "00317\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00318\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00319\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00320\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00321\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00322\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00323\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00324\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00325\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00326\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00327\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00328\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00329\t            );\n",
      "00330\t                {\n",
      "00331\t        __failure = 6;\n",
      "00332\t        if (!PyErr_Occurred()) {\n",
      "00333\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00334\t                \"Unexpected error in an Op's C code. \"\n",
      "00335\t                \"No Python exception was set.\");\n",
      "00336\t            }\n",
      "00337\t        goto __label_6;}\n",
      "00338\t            }\n",
      "00339\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00340\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00341\t            if (PyArray_TYPE((PyArrayObject*) py_V5) != NPY_FLOAT64) {\n",
      "00342\t                PyErr_Format(PyExc_TypeError,\n",
      "00343\t                             \"expected type_num %d (NPY_FLOAT64) got %d\",\n",
      "00344\t                             NPY_FLOAT64, PyArray_TYPE((PyArrayObject*) py_V5));\n",
      "00345\t                {\n",
      "00346\t        __failure = 6;\n",
      "00347\t        if (!PyErr_Occurred()) {\n",
      "00348\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00349\t                \"Unexpected error in an Op's C code. \"\n",
      "00350\t                \"No Python exception was set.\");\n",
      "00351\t            }\n",
      "00352\t        goto __label_6;}\n",
      "00353\t            }\n",
      "00354\t            \n",
      "00355\t        V5 = (PyArrayObject*)(py_V5);\n",
      "00356\t        Py_XINCREF(V5);\n",
      "00357\t        \n",
      "00358\t{\n",
      "00359\t\n",
      "00360\t    py_V7 = PyList_GET_ITEM(storage_V7, 0);\n",
      "00361\t    {Py_XINCREF(py_V7);}\n",
      "00362\t    \n",
      "00363\t            V7 = NULL;\n",
      "00364\t            if (py_V7 == Py_None) {\n",
      "00365\t                // We can either fail here or set V7 to NULL and rely on Ops\n",
      "00366\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00367\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00368\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00369\t                {\n",
      "00370\t        __failure = 8;\n",
      "00371\t        if (!PyErr_Occurred()) {\n",
      "00372\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00373\t                \"Unexpected error in an Op's C code. \"\n",
      "00374\t                \"No Python exception was set.\");\n",
      "00375\t            }\n",
      "00376\t        goto __label_8;}\n",
      "00377\t            }\n",
      "00378\t            if (!PyArray_Check(py_V7)) {\n",
      "00379\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00380\t                {\n",
      "00381\t        __failure = 8;\n",
      "00382\t        if (!PyErr_Occurred()) {\n",
      "00383\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00384\t                \"Unexpected error in an Op's C code. \"\n",
      "00385\t                \"No Python exception was set.\");\n",
      "00386\t            }\n",
      "00387\t        goto __label_8;}\n",
      "00388\t            }\n",
      "00389\t            // We expect NPY_FLOAT64\n",
      "00390\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V7)) {\n",
      "00391\t                PyArrayObject * tmp = (PyArrayObject*) py_V7;\n",
      "00392\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00393\t                             \"expected an aligned array of type %ld \"\n",
      "00394\t                             \"(NPY_FLOAT64), got non-aligned array of type %ld\"\n",
      "00395\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00396\t                             \"%ld, %ld, %ld\"\n",
      "00397\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00398\t                             (long int) NPY_FLOAT64,\n",
      "00399\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V7),\n",
      "00400\t                             (long int) PyArray_NDIM(tmp),\n",
      "00401\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00402\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00403\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00404\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00405\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00406\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00407\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00408\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00409\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00410\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00411\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00412\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00413\t            );\n",
      "00414\t                {\n",
      "00415\t        __failure = 8;\n",
      "00416\t        if (!PyErr_Occurred()) {\n",
      "00417\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00418\t                \"Unexpected error in an Op's C code. \"\n",
      "00419\t                \"No Python exception was set.\");\n",
      "00420\t            }\n",
      "00421\t        goto __label_8;}\n",
      "00422\t            }\n",
      "00423\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00424\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00425\t            if (PyArray_TYPE((PyArrayObject*) py_V7) != NPY_FLOAT64) {\n",
      "00426\t                PyErr_Format(PyExc_TypeError,\n",
      "00427\t                             \"expected type_num %d (NPY_FLOAT64) got %d\",\n",
      "00428\t                             NPY_FLOAT64, PyArray_TYPE((PyArrayObject*) py_V7));\n",
      "00429\t                {\n",
      "00430\t        __failure = 8;\n",
      "00431\t        if (!PyErr_Occurred()) {\n",
      "00432\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00433\t                \"Unexpected error in an Op's C code. \"\n",
      "00434\t                \"No Python exception was set.\");\n",
      "00435\t            }\n",
      "00436\t        goto __label_8;}\n",
      "00437\t            }\n",
      "00438\t            \n",
      "00439\t        V7 = (PyArrayObject*)(py_V7);\n",
      "00440\t        Py_XINCREF(V7);\n",
      "00441\t        \n",
      "00442\t{\n",
      "00443\t// Op class Elemwise\n",
      "00444\t\n",
      "00445\t        npy_float64* V3_iter;\n",
      "00446\t        \n",
      "00447\t                int V3_jumpx_0;\n",
      "00448\t                \n",
      "00449\t                int V3_jumpx_1;\n",
      "00450\t                \n",
      "00451\t        npy_float64* V5_iter;\n",
      "00452\t        \n",
      "00453\t                npy_intp V5_n0;\n",
      "00454\t                ssize_t V5_stride0;\n",
      "00455\t                int V5_jump0_0;\n",
      "00456\t                \n",
      "00457\t                npy_intp V5_n1;\n",
      "00458\t                ssize_t V5_stride1;\n",
      "00459\t                int V5_jump1_1;\n",
      "00460\t                \n",
      "00461\t        npy_float64* V7_iter;\n",
      "00462\t        \n",
      "00463\t                npy_intp V7_n0;\n",
      "00464\t                ssize_t V7_stride0;\n",
      "00465\t                int V7_jump0_0;\n",
      "00466\t                \n",
      "00467\t                npy_intp V7_n1;\n",
      "00468\t                ssize_t V7_stride1;\n",
      "00469\t                int V7_jump1_1;\n",
      "00470\t                \n",
      "00471\t\n",
      "00472\t                V3_jumpx_1 = -(0);\n",
      "00473\t                //printf(\"V3_jumpx_1 is:\");\n",
      "00474\t                //std::cout << V3_jumpx_1 << std::endl;\n",
      "00475\t                \n",
      "00476\t                V3_jumpx_0 = -(0);\n",
      "00477\t                //printf(\"V3_jumpx_0 is:\");\n",
      "00478\t                //std::cout << V3_jumpx_0 << std::endl;\n",
      "00479\t                \n",
      "00480\t            if (PyArray_NDIM(V5) < 2) {\n",
      "00481\t                PyErr_SetString(PyExc_ValueError, \"Not enough dimensions on input.\");\n",
      "00482\t                {\n",
      "00483\t        __failure = 9;\n",
      "00484\t        if (!PyErr_Occurred()) {\n",
      "00485\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00486\t                \"Unexpected error in an Op's C code. \"\n",
      "00487\t                \"No Python exception was set.\");\n",
      "00488\t            }\n",
      "00489\t        goto __label_9;}\n",
      "00490\t            }\n",
      "00491\t            \n",
      "00492\t                V5_n1 = PyArray_DIMS(V5)[1];\n",
      "00493\t                V5_stride1 = PyArray_STRIDES(V5)[1] / sizeof(npy_float64);\n",
      "00494\t                V5_jump1_1 = (V5_stride1) - (0);\n",
      "00495\t                //printf(\"V5_jump1_1 is:\");\n",
      "00496\t                //std::cout << V5_jump1_1 << std::endl;\n",
      "00497\t                \n",
      "00498\t                V5_n0 = PyArray_DIMS(V5)[0];\n",
      "00499\t                V5_stride0 = PyArray_STRIDES(V5)[0] / sizeof(npy_float64);\n",
      "00500\t                V5_jump0_0 = (V5_stride0) - (V5_n1*V5_stride1);\n",
      "00501\t                //printf(\"V5_jump0_0 is:\");\n",
      "00502\t                //std::cout << V5_jump0_0 << std::endl;\n",
      "00503\t                \n",
      "00504\t            if (PyArray_NDIM(V7) < 2) {\n",
      "00505\t                PyErr_SetString(PyExc_ValueError, \"Not enough dimensions on input.\");\n",
      "00506\t                {\n",
      "00507\t        __failure = 9;\n",
      "00508\t        if (!PyErr_Occurred()) {\n",
      "00509\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00510\t                \"Unexpected error in an Op's C code. \"\n",
      "00511\t                \"No Python exception was set.\");\n",
      "00512\t            }\n",
      "00513\t        goto __label_9;}\n",
      "00514\t            }\n",
      "00515\t            \n",
      "00516\t                V7_n1 = PyArray_DIMS(V7)[1];\n",
      "00517\t                V7_stride1 = PyArray_STRIDES(V7)[1] / sizeof(npy_float64);\n",
      "00518\t                V7_jump1_1 = (V7_stride1) - (0);\n",
      "00519\t                //printf(\"V7_jump1_1 is:\");\n",
      "00520\t                //std::cout << V7_jump1_1 << std::endl;\n",
      "00521\t                \n",
      "00522\t                V7_n0 = PyArray_DIMS(V7)[0];\n",
      "00523\t                V7_stride0 = PyArray_STRIDES(V7)[0] / sizeof(npy_float64);\n",
      "00524\t                V7_jump0_0 = (V7_stride0) - (V7_n1*V7_stride1);\n",
      "00525\t                //printf(\"V7_jump0_0 is:\");\n",
      "00526\t                //std::cout << V7_jump0_0 << std::endl;\n",
      "00527\t                \n",
      "00528\t            if (V5_n0 != V7_n0)\n",
      "00529\t            {\n",
      "00530\t                PyErr_Format(PyExc_ValueError, \"Input dimension mis-match. (input[%i].shape[%i] = %i, input[%i].shape[%i] = %i)\",\n",
      "00531\t                   1,\n",
      "00532\t                   0,\n",
      "00533\t                   V5_n0,\n",
      "00534\t                   2,\n",
      "00535\t                   0,\n",
      "00536\t                   V7_n0\n",
      "00537\t                );\n",
      "00538\t                {\n",
      "00539\t        __failure = 9;\n",
      "00540\t        if (!PyErr_Occurred()) {\n",
      "00541\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00542\t                \"Unexpected error in an Op's C code. \"\n",
      "00543\t                \"No Python exception was set.\");\n",
      "00544\t            }\n",
      "00545\t        goto __label_9;}\n",
      "00546\t            }\n",
      "00547\t            \n",
      "00548\t            if (V5_n1 != V7_n1)\n",
      "00549\t            {\n",
      "00550\t                PyErr_Format(PyExc_ValueError, \"Input dimension mis-match. (input[%i].shape[%i] = %i, input[%i].shape[%i] = %i)\",\n",
      "00551\t                   1,\n",
      "00552\t                   1,\n",
      "00553\t                   V5_n1,\n",
      "00554\t                   2,\n",
      "00555\t                   1,\n",
      "00556\t                   V7_n1\n",
      "00557\t                );\n",
      "00558\t                {\n",
      "00559\t        __failure = 9;\n",
      "00560\t        if (!PyErr_Occurred()) {\n",
      "00561\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00562\t                \"Unexpected error in an Op's C code. \"\n",
      "00563\t                \"No Python exception was set.\");\n",
      "00564\t            }\n",
      "00565\t        goto __label_9;}\n",
      "00566\t            }\n",
      "00567\t            \n",
      "00568\t\n",
      "00569\t            if (V1) {\n",
      "00570\t                Py_XDECREF(V1);\n",
      "00571\t            }\n",
      "00572\t            V1 = V7;\n",
      "00573\t            Py_XINCREF(V1);\n",
      "00574\t            \n",
      "00575\t\n",
      "00576\t            if((PyArray_ISCONTIGUOUS(V5) && PyArray_ISCONTIGUOUS(V7) && PyArray_ISCONTIGUOUS(V1)) || (PyArray_ISFORTRAN(V5) && PyArray_ISFORTRAN(V7) && PyArray_ISFORTRAN(V1))){\n",
      "00577\t                \n",
      "00578\t                    // All output have the same size\n",
      "00579\t                    npy_intp n = PyArray_SIZE(V1);\n",
      "00580\t                    \n",
      "00581\t            dtype_V3& V3_i = ((dtype_V3*) PyArray_DATA(V3))[0];\n",
      "00582\t                            \n",
      "00583\t            dtype_V5 * V5_ptr = (dtype_V5*) PyArray_DATA(V5);\n",
      "00584\t                            \n",
      "00585\t            dtype_V7 * V7_ptr = (dtype_V7*) PyArray_DATA(V7);\n",
      "00586\t                            \n",
      "00587\t            dtype_V1 * V1_ptr = (dtype_V1*) PyArray_DATA(V1);\n",
      "00588\t                            \n",
      "00589\t                    for(int i=0; i<n; i++){\n",
      "00590\t                        \n",
      "00591\t            dtype_V5& V5_i = V5_ptr[i];\n",
      "00592\t                            \n",
      "00593\t            dtype_V7& V7_i = V7_ptr[i];\n",
      "00594\t                            \n",
      "00595\t            dtype_V1& V1_i = V1_ptr[i];\n",
      "00596\t                            \n",
      "00597\t                        {\n",
      "00598\tnpy_float64 V9_tmp1;\n",
      "00599\tV9_tmp1 = V3_i - V5_i;\n",
      "00600\tV1_i = V9_tmp1 * V7_i * V5_i;\n",
      "00601\t}\n",
      "00602\t;\n",
      "00603\t                    }\n",
      "00604\t                    \n",
      "00605\t            }else{\n",
      "00606\t                {\n",
      "00607\t\n",
      "00608\t    std::vector< std::pair<int, int> > V7_loops(2);\n",
      "00609\t    std::vector< std::pair<int, int> >::iterator V7_loops_it = V7_loops.begin();\n",
      "00610\t    \n",
      "00611\t            V7_loops_it->first = abs(PyArray_STRIDES(V7)[0]);\n",
      "00612\t            \n",
      "00613\t        V7_loops_it->second = 0;\n",
      "00614\t        ++V7_loops_it;\n",
      "00615\t        \n",
      "00616\t            V7_loops_it->first = abs(PyArray_STRIDES(V7)[1]);\n",
      "00617\t            \n",
      "00618\t        V7_loops_it->second = 1;\n",
      "00619\t        ++V7_loops_it;\n",
      "00620\t        \n",
      "00621\t    // rbegin and rend are reversed iterators, so this sorts in decreasing order\n",
      "00622\t    std::sort(V7_loops.rbegin(), V7_loops.rend());\n",
      "00623\t    \n",
      "00624\t\n",
      "00625\t    int init_totals[2] = {V5_n0, V5_n1};\n",
      "00626\t    \n",
      "00627\t    V7_loops_it = V7_loops.begin();\n",
      "00628\t    \n",
      "00629\t        int TOTAL_0 = init_totals[V7_loops_it->second];\n",
      "00630\t        ++V7_loops_it;\n",
      "00631\t        \n",
      "00632\t        int TOTAL_1 = init_totals[V7_loops_it->second];\n",
      "00633\t        ++V7_loops_it;\n",
      "00634\t        \n",
      "00635\t\n",
      "00636\t    int init_strides[3][2] = {\n",
      "00637\t        0, 0, \n",
      "00638\tV5_stride0, V5_stride1, \n",
      "00639\tV7_stride0, V7_stride1\n",
      "00640\t    };\n",
      "00641\t    std::vector< std::pair<int, int> >::reverse_iterator V7_loops_rit;\n",
      "00642\t    \n",
      "00643\t        V7_loops_rit = V7_loops.rbegin();\n",
      "00644\t            int V3_stride_l1 = init_strides[0][V7_loops_rit->second];\n",
      "00645\t            ++V7_loops_rit;\n",
      "00646\t            \n",
      "00647\t            int V3_stride_l0 = init_strides[0][V7_loops_rit->second];\n",
      "00648\t            ++V7_loops_rit;\n",
      "00649\t            \n",
      "00650\t        V7_loops_rit = V7_loops.rbegin();\n",
      "00651\t            int V5_stride_l1 = init_strides[1][V7_loops_rit->second];\n",
      "00652\t            ++V7_loops_rit;\n",
      "00653\t            \n",
      "00654\t            int V5_stride_l0 = init_strides[1][V7_loops_rit->second];\n",
      "00655\t            ++V7_loops_rit;\n",
      "00656\t            \n",
      "00657\t        V7_loops_rit = V7_loops.rbegin();\n",
      "00658\t            int V7_stride_l1 = init_strides[2][V7_loops_rit->second];\n",
      "00659\t            ++V7_loops_rit;\n",
      "00660\t            \n",
      "00661\t            int V7_stride_l0 = init_strides[2][V7_loops_rit->second];\n",
      "00662\t            ++V7_loops_rit;\n",
      "00663\t            \n",
      "00664\tV3_iter = (npy_float64*)(PyArray_DATA(V3));\n",
      "00665\tV5_iter = (npy_float64*)(PyArray_DATA(V5));\n",
      "00666\tV7_iter = (npy_float64*)(PyArray_DATA(V7));\n",
      "00667\t\n",
      "00668\t\n",
      "00669\t        for(int ITER_0 = 0; ITER_0<TOTAL_0; ITER_0++)\n",
      "00670\t        { // begin loop 0\n",
      "00671\t            \n",
      "00672\t            \n",
      "00673\t        for(int ITER_1 = 0; ITER_1<TOTAL_1; ITER_1++)\n",
      "00674\t        { // begin loop 1\n",
      "00675\t            npy_float64 &V3_i = * ( V3_iter+V3_stride_l1*ITER_1+V3_stride_l0*ITER_0);\n",
      "00676\tnpy_float64 &V5_i = * ( V5_iter+V5_stride_l1*ITER_1+V5_stride_l0*ITER_0);\n",
      "00677\tnpy_float64 &V7_i = * ( V7_iter+V7_stride_l1*ITER_1+V7_stride_l0*ITER_0);\n",
      "00678\t\n",
      "00679\t            \n",
      "00680\t        {\n",
      "00681\t            #define V1_i V7_i\n",
      "00682\t            {\n",
      "00683\tnpy_float64 V9_tmp1;\n",
      "00684\tV9_tmp1 = V3_i - V5_i;\n",
      "00685\tV1_i = V9_tmp1 * V7_i * V5_i;\n",
      "00686\t}\n",
      "00687\t\n",
      "00688\t            #undef V1_i\n",
      "00689\t        }\n",
      "00690\t         \n",
      "00691\t        } // end loop 1\n",
      "00692\t         \n",
      "00693\t        } // end loop 0\n",
      "00694\t        \n",
      "00695\t}\n",
      "00696\t\n",
      "00697\t            }\n",
      "00698\t            __label_9:\n",
      "00699\t\n",
      "00700\tdouble __DUMMY_9;\n",
      "00701\t\n",
      "00702\t}\n",
      "00703\t__label_8:\n",
      "00704\t\n",
      "00705\t        if (V7) {\n",
      "00706\t            Py_XDECREF(V7);\n",
      "00707\t        }\n",
      "00708\t        \n",
      "00709\t    {Py_XDECREF(py_V7);}\n",
      "00710\t    \n",
      "00711\tdouble __DUMMY_8;\n",
      "00712\t\n",
      "00713\t}\n",
      "00714\t__label_6:\n",
      "00715\t\n",
      "00716\t        if (V5) {\n",
      "00717\t            Py_XDECREF(V5);\n",
      "00718\t        }\n",
      "00719\t        \n",
      "00720\t    {Py_XDECREF(py_V5);}\n",
      "00721\t    \n",
      "00722\tdouble __DUMMY_6;\n",
      "00723\t\n",
      "00724\t}\n",
      "00725\t__label_4:\n",
      "00726\t\n",
      "00727\t        if (V3) {\n",
      "00728\t            Py_XDECREF(V3);\n",
      "00729\t        }\n",
      "00730\t        \n",
      "00731\t    {Py_XDECREF(py_V3);}\n",
      "00732\t    \n",
      "00733\tdouble __DUMMY_4;\n",
      "00734\t\n",
      "00735\t}\n",
      "00736\t__label_2:\n",
      "00737\t\n",
      "00738\t    if (!__failure) {\n",
      "00739\t      \n",
      "00740\t        {Py_XDECREF(py_V1);}\n",
      "00741\t        if (!V1) {\n",
      "00742\t            Py_INCREF(Py_None);\n",
      "00743\t            py_V1 = Py_None;\n",
      "00744\t        }\n",
      "00745\t        else if ((void*)py_V1 != (void*)V1) {\n",
      "00746\t            py_V1 = (PyObject*)V1;\n",
      "00747\t        }\n",
      "00748\t\n",
      "00749\t        {Py_XINCREF(py_V1);}\n",
      "00750\t\n",
      "00751\t        if (V1 && !PyArray_ISALIGNED((PyArrayObject*) py_V1)) {\n",
      "00752\t            PyErr_Format(PyExc_NotImplementedError,\n",
      "00753\t                         \"c_sync: expected an aligned array, got non-aligned array of type %ld\"\n",
      "00754\t                         \" with %ld dimensions, with 3 last dims \"\n",
      "00755\t                         \"%ld, %ld, %ld\"\n",
      "00756\t                         \" and 3 last strides %ld %ld, %ld.\",\n",
      "00757\t                         (long int) PyArray_TYPE((PyArrayObject*) py_V1),\n",
      "00758\t                         (long int) PyArray_NDIM(V1),\n",
      "00759\t                         (long int) PyArray_NDIM(V1) >= 3 ?\n",
      "00760\t        PyArray_DIMS(V1)[PyArray_NDIM(V1)-3] : -1,\n",
      "00761\t                         (long int) PyArray_NDIM(V1) >= 2 ?\n",
      "00762\t        PyArray_DIMS(V1)[PyArray_NDIM(V1)-2] : -1,\n",
      "00763\t                         (long int) PyArray_NDIM(V1) >= 1 ?\n",
      "00764\t        PyArray_DIMS(V1)[PyArray_NDIM(V1)-1] : -1,\n",
      "00765\t                         (long int) PyArray_NDIM(V1) >= 3 ?\n",
      "00766\t        PyArray_STRIDES(V1)[PyArray_NDIM(V1)-3] : -1,\n",
      "00767\t                         (long int) PyArray_NDIM(V1) >= 2 ?\n",
      "00768\t        PyArray_STRIDES(V1)[PyArray_NDIM(V1)-2] : -1,\n",
      "00769\t                         (long int) PyArray_NDIM(V1) >= 1 ?\n",
      "00770\t        PyArray_STRIDES(V1)[PyArray_NDIM(V1)-1] : -1\n",
      "00771\t        );\n",
      "00772\t            {\n",
      "00773\t        __failure = 2;\n",
      "00774\t        if (!PyErr_Occurred()) {\n",
      "00775\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00776\t                \"Unexpected error in an Op's C code. \"\n",
      "00777\t                \"No Python exception was set.\");\n",
      "00778\t            }\n",
      "00779\t        goto __label_2;}\n",
      "00780\t        }\n",
      "00781\t        \n",
      "00782\t      PyObject* old = PyList_GET_ITEM(storage_V1, 0);\n",
      "00783\t      {Py_XINCREF(py_V1);}\n",
      "00784\t      PyList_SET_ITEM(storage_V1, 0, py_V1);\n",
      "00785\t      {Py_XDECREF(old);}\n",
      "00786\t    }\n",
      "00787\t    \n",
      "00788\t        if (V1) {\n",
      "00789\t            Py_XDECREF(V1);\n",
      "00790\t        }\n",
      "00791\t        \n",
      "00792\t    {Py_XDECREF(py_V1);}\n",
      "00793\t    \n",
      "00794\tdouble __DUMMY_2;\n",
      "00795\t\n",
      "00796\t}\n",
      "00797\t\n",
      "00798\t            \n",
      "00799\t        if (__failure) {\n",
      "00800\t            // When there is a failure, this code puts the exception\n",
      "00801\t            // in __ERROR.\n",
      "00802\t            PyObject* err_type = NULL;\n",
      "00803\t            PyObject* err_msg = NULL;\n",
      "00804\t            PyObject* err_traceback = NULL;\n",
      "00805\t            PyErr_Fetch(&err_type, &err_msg, &err_traceback);\n",
      "00806\t            if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);}\n",
      "00807\t            if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);}\n",
      "00808\t            if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);}\n",
      "00809\t            PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0);\n",
      "00810\t            PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1);\n",
      "00811\t            PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2);\n",
      "00812\t            PyList_SET_ITEM(__ERROR, 0, err_type);\n",
      "00813\t            PyList_SET_ITEM(__ERROR, 1, err_msg);\n",
      "00814\t            PyList_SET_ITEM(__ERROR, 2, err_traceback);\n",
      "00815\t            {Py_XDECREF(old_err_type);}\n",
      "00816\t            {Py_XDECREF(old_err_msg);}\n",
      "00817\t            {Py_XDECREF(old_err_traceback);}\n",
      "00818\t        }\n",
      "00819\t        // The failure code is returned to index what code block failed.\n",
      "00820\t        return __failure;\n",
      "00821\t        \n",
      "00822\t        }\n",
      "00823\t    };\n",
      "00824\t    }\n",
      "00825\t    \n",
      "00826\t\n",
      "00827\t        static int __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673_executor(__struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673* self) {\n",
      "00828\t            return self->run();\n",
      "00829\t        }\n",
      "00830\t\n",
      "00831\t        static void __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673_destructor(void* executor, void* self) {\n",
      "00832\t            delete ((__struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673*)self);\n",
      "00833\t        }\n",
      "00834\t        \n",
      "00835\t//////////////////////\n",
      "00836\t////  Functions\n",
      "00837\t//////////////////////\n",
      "00838\tstatic PyObject * instantiate(PyObject * self, PyObject *argtuple) {\n",
      "00839\t  assert(PyTuple_Check(argtuple));\n",
      "00840\t  if (5 != PyTuple_Size(argtuple)){ \n",
      "00841\t     PyErr_Format(PyExc_TypeError, \"Wrong number of arguments, expected 5, got %i\", (int)PyTuple_Size(argtuple));\n",
      "00842\t     return NULL;\n",
      "00843\t  }\n",
      "00844\t  __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673* struct_ptr = new __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673();\n",
      "00845\t  if (struct_ptr->init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1),PyTuple_GET_ITEM(argtuple, 2),PyTuple_GET_ITEM(argtuple, 3),PyTuple_GET_ITEM(argtuple, 4) ) != 0) {\n",
      "00846\t    delete struct_ptr;\n",
      "00847\t    return NULL;\n",
      "00848\t  }\n",
      "00849\t  PyObject* thunk = PyCObject_FromVoidPtrAndDesc((void*)(&__struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673_executor), struct_ptr, __struct_compiled_op_f01e4aaec27b6932023ba77f6d2a9673_destructor);\n",
      "00850\t  return thunk; }\n",
      "00851\t\n",
      "00852\t//////////////////////\n",
      "00853\t////  Module init\n",
      "00854\t//////////////////////\n",
      "00855\tstatic PyMethodDef MyMethods[] = {\n",
      "00856\t\t{\"instantiate\", instantiate, METH_VARARGS, \"undocumented\"} ,\n",
      "00857\t\t{NULL, NULL, 0, NULL}\n",
      "00858\t};\n",
      "00859\tPyMODINIT_FUNC initf01e4aaec27b6932023ba77f6d2a9673(void){\n",
      "00860\t   import_array();\n",
      "00861\t   (void) Py_InitModule(\"f01e4aaec27b6932023ba77f6d2a9673\", MyMethods);\n",
      "00862\t}\n",
      "00863\t\n",
      "Problem occurred during compilation with the command line below:\n",
      "D:\\mingw64\\bin\\g++.exe -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -march=corei7-avx -mcx16 -msahf -mno-movbe -maes -mpclmul -mpopcnt -mno-abm -mno-lwp -mno-fma -mno-fma4 -mno-xop -mno-bmi -mno-bmi2 -mno-tbm -mavx -mno-avx2 -msse4.2 -msse4.1 -mno-lzcnt -mno-rtm -mno-hle -mrdrnd -mf16c -mfsgsbase -mno-rdseed -mno-prfchw -mno-adx -mfxsr -mxsave -mxsaveopt --param l1-cache-size=0 --param l1-cache-line-size=0 --param l2-cache-size=256 -mtune=generic -D NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -DMS_WIN64 -ID:\\Anaconda\\lib\\site-packages\\numpy\\core\\include -ID:\\Anaconda\\include -o C:\\Users\\ray306\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.10-64\\tmprf8xbk\\f01e4aaec27b6932023ba77f6d2a9673.pyd C:\\Users\\ray306\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.10-64\\tmprf8xbk\\mod.cpp -LD:\\Anaconda\\libs -LD:\\Anaconda -lpython27\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "('The following error happened while compiling the node', Elemwise{Composite{((i0 - i1) * i2 * i1)}}[(0, 2)](TensorConstant{(1L, 1L) of 1.0}, Elemwise{Composite{scalar_sigmoid((i0 + i1))}}.0, AdvancedIncSubtensor1{inplace,inc}.0), '\\n', 'Compilation failed (return status=-1073741510): ^C', '[Elemwise{Composite{((i0 - i1) * i2 * i1)}}[(0, 2)](TensorConstant{(1L, 1L) of 1.0}, <TensorType(float64, matrix)>, <TensorType(float64, matrix)>)]')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-93d144e1ad06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, class_mode, theano_mode)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         self._train = theano.function(train_ins, train_loss, updates=updates,\n\u001b[1;32m--> 400\u001b[1;33m                                       allow_input_downcast=True, mode=theano_mode)\n\u001b[0m\u001b[0;32m    401\u001b[0m         self._train_with_acc = theano.function(train_ins, [train_loss, train_accuracy], updates=updates,\n\u001b[0;32m    402\u001b[0m                                                allow_input_downcast=True, mode=theano_mode)\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[0;32m   1464\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1466\u001b[1;33m                        defaults)\n\u001b[0m\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, input_storage, trustme)\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[1;32m-> 1324\u001b[1;33m                 input_storage=input_storage_lists)\n\u001b[0m\u001b[0;32m   1325\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_thunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[1;32m--> 519\u001b[1;33m                              output_storage=output_storage)[:3]\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(self, profiler, input_storage, output_storage)\u001b[0m\n\u001b[0;32m    895\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m                                                  no_recycling))\n\u001b[0m\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lazy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m                     \u001b[1;31m# We don't want all ops maker to think about lazy Ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_self_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return super(OpenMPOp, self).make_thunk(node, storage_map,\n\u001b[1;32m-> 1002\u001b[1;33m                                                 compute_map, no_recycling)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m                 outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[1;32m--> 739\u001b[1;33m                                         output_storage=node_output_storage)\n\u001b[0m\u001b[0;32m    740\u001b[0m                 \u001b[0mfill_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, keep_lock)\u001b[0m\n\u001b[0;32m   1071\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[0;32m   1072\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m             keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36m__compile__\u001b[1;34m(self, input_storage, output_storage, keep_lock)\u001b[0m\n\u001b[0;32m   1013\u001b[0m                                     \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1016\u001b[0m         return (thunk,\n\u001b[0;32m   1017\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36mcthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, keep_lock)\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[1;32m-> 1442\u001b[1;33m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m         \u001b[0mvars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cmodule.pyc\u001b[0m in \u001b[0;36mmodule_from_key\u001b[1;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m                 preargs=preargs)\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cmodule.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module)\u001b[0m\n\u001b[0;32m   2008\u001b[0m             \u001b[1;31m# difficult to read.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m             raise Exception('Compilation failed (return status=%s): %s' %\n\u001b[1;32m-> 2010\u001b[1;33m                             (status, compile_stderr.replace('\\n', '. ')))\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompilation_warning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompile_stderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m             \u001b[1;31m# Print errors just below the command line.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: ('The following error happened while compiling the node', Elemwise{Composite{((i0 - i1) * i2 * i1)}}[(0, 2)](TensorConstant{(1L, 1L) of 1.0}, Elemwise{Composite{scalar_sigmoid((i0 + i1))}}.0, AdvancedIncSubtensor1{inplace,inc}.0), '\\n', 'Compilation failed (return status=-1073741510): ^C', '[Elemwise{Composite{((i0 - i1) * i2 * i1)}}[(0, 2)](TensorConstant{(1L, 1L) of 1.0}, <TensorType(float64, matrix)>, <TensorType(float64, matrix)>)]')"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "# Add a mask_zero=True to the Embedding connstructor if 0 is a left-padding value in your data\n",
    "model.add(Embedding(10, 10))\n",
    "model.add(LSTM(10, 10, activation='sigmoid', inner_activation='hard_sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=1, nb_epoch=1)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.\n",
    "X_train = [[-3,-2,-1],[4,5,6],[11,12,13],[1,0,3],[4,3,6],[7,6,9]]\n",
    "Y_train = [1,1,1,2,2,2]\n",
    "\n",
    "X_test = [[7,8,9],[1,2,3],[4,5,6],[2,1,3],[11,9,13]]\n",
    "Y_test = [1,1,1,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random\n",
    "X_train = [[-3,-2,-1],[4,5,6],[11,12,13],[1,0,3],[4,3,6],[7,6,9]]\n",
    "Y_train = [1,1,1,2,2,2]\n",
    "\n",
    "X_test = [[7,8,9],[1,2,3],[4,5,6],[2,1,3],[11,9,13]]\n",
    "Y_test = [1,1,1,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c6216644d47a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'datasets'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "t = keras.datasets.cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['step']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "D:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:398: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <type 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (theano.compat.python2x.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Elapsed time: 109.829000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEKCAYAAAALoA6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXKPRaHIo/w+MbzPDnBM8UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f52c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Vanilla RNN\n",
    "@author Graham Taylor\n",
    "\"\"\"\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.base import BaseEstimator\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import cPickle as pickle\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "mode = theano.Mode(linker='cvm')\n",
    "#mode = 'DEBUG_MODE'\n",
    "\n",
    "\n",
    "class RNN(object):\n",
    "    \"\"\"    Recurrent neural network class\n",
    "    Supported output types:\n",
    "    real : linear output units, use mean-squared error\n",
    "    binary : binary output units, use cross-entropy error\n",
    "    softmax : single softmax out, use cross-entropy error\n",
    "    \"\"\"\n",
    "    def __init__(self, input, n_in, n_hidden, n_out, activation=T.tanh,\n",
    "                 output_type='real', use_symbolic_softmax=False):\n",
    "\n",
    "        self.input = input\n",
    "        self.activation = activation\n",
    "        self.output_type = output_type\n",
    "\n",
    "        # when using HF, SoftmaxGrad.grad is not implemented\n",
    "        # use a symbolic softmax which is slightly slower than T.nnet.softmax\n",
    "        # See: http://groups.google.com/group/theano-dev/browse_thread/\n",
    "        # thread/3930bd5a6a67d27a\n",
    "        if use_symbolic_softmax:\n",
    "            def symbolic_softmax(x):\n",
    "                e = T.exp(x)\n",
    "                return e / T.sum(e, axis=1).dimshuffle(0, 'x')\n",
    "            self.softmax = symbolic_softmax\n",
    "        else:\n",
    "            self.softmax = T.nnet.softmax\n",
    "\n",
    "        # recurrent weights as a shared variable\n",
    "        W_init = np.asarray(np.random.uniform(size=(n_hidden, n_hidden),\n",
    "                                              low=-.01, high=.01),\n",
    "                                              dtype=theano.config.floatX)\n",
    "        self.W = theano.shared(value=W_init, name='W')\n",
    "        # input to hidden layer weights\n",
    "        W_in_init = np.asarray(np.random.uniform(size=(n_in, n_hidden),\n",
    "                                                 low=-.01, high=.01),\n",
    "                                                 dtype=theano.config.floatX)\n",
    "        self.W_in = theano.shared(value=W_in_init, name='W_in')\n",
    "\n",
    "        # hidden to output layer weights\n",
    "        W_out_init = np.asarray(np.random.uniform(size=(n_hidden, n_out),\n",
    "                                                  low=-.01, high=.01),\n",
    "                                                  dtype=theano.config.floatX)\n",
    "        self.W_out = theano.shared(value=W_out_init, name='W_out')\n",
    "\n",
    "        h0_init = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        self.h0 = theano.shared(value=h0_init, name='h0')\n",
    "\n",
    "        bh_init = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        self.bh = theano.shared(value=bh_init, name='bh')\n",
    "\n",
    "        by_init = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "        self.by = theano.shared(value=by_init, name='by')\n",
    "\n",
    "        self.params = [self.W, self.W_in, self.W_out, self.h0,\n",
    "                       self.bh, self.by]\n",
    "\n",
    "        # for every parameter, we maintain it's last update\n",
    "        # the idea here is to use \"momentum\"\n",
    "        # keep moving mostly in the same direction\n",
    "        self.updates = {}\n",
    "        for param in self.params:\n",
    "            init = np.zeros(param.get_value(borrow=True).shape,\n",
    "                            dtype=theano.config.floatX)\n",
    "            self.updates[param] = theano.shared(init)\n",
    "\n",
    "        # recurrent function (using tanh activation function) and linear output\n",
    "        # activation function\n",
    "        def step(x_t, h_tm1):\n",
    "            h_t = self.activation(T.dot(x_t, self.W_in) + \\\n",
    "                                  T.dot(h_tm1, self.W) + self.bh)\n",
    "            y_t = T.dot(h_t, self.W_out) + self.by\n",
    "            return h_t, y_t\n",
    "\n",
    "        # the hidden state `h` for the entire sequence, and the output for the\n",
    "        # entire sequence `y` (first dimension is always time)\n",
    "        [self.h, self.y_pred], _ = theano.scan(step,\n",
    "                                               sequences=self.input,\n",
    "                                               outputs_info=[self.h0, None])\n",
    "\n",
    "        # L1 norm ; one regularization option is to enforce L1 norm to\n",
    "        # be small\n",
    "        self.L1 = 0\n",
    "        self.L1 += abs(self.W.sum())\n",
    "        self.L1 += abs(self.W_in.sum())\n",
    "        self.L1 += abs(self.W_out.sum())\n",
    "\n",
    "        # square of L2 norm ; one regularization option is to enforce\n",
    "        # square of L2 norm to be small\n",
    "        self.L2_sqr = 0\n",
    "        self.L2_sqr += (self.W ** 2).sum()\n",
    "        self.L2_sqr += (self.W_in ** 2).sum()\n",
    "        self.L2_sqr += (self.W_out ** 2).sum()\n",
    "\n",
    "        if self.output_type == 'real':\n",
    "            self.loss = lambda y: self.mse(y)\n",
    "        elif self.output_type == 'binary':\n",
    "            # push through sigmoid\n",
    "            self.p_y_given_x = T.nnet.sigmoid(self.y_pred)  # apply sigmoid\n",
    "            self.y_out = T.round(self.p_y_given_x)  # round to {0,1}\n",
    "            self.loss = lambda y: self.nll_binary(y)\n",
    "        elif self.output_type == 'softmax':\n",
    "            # push through softmax, computing vector of class-membership\n",
    "            # probabilities in symbolic form\n",
    "            self.p_y_given_x = self.softmax(self.y_pred)\n",
    "\n",
    "            # compute prediction as class whose probability is maximal\n",
    "            self.y_out = T.argmax(self.p_y_given_x, axis=-1)\n",
    "            self.loss = lambda y: self.nll_multiclass(y)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def mse(self, y):\n",
    "        # error between output and target\n",
    "        return T.mean((self.y_pred - y) ** 2)\n",
    "\n",
    "    def nll_binary(self, y):\n",
    "        # negative log likelihood based on binary cross entropy error\n",
    "        return T.mean(T.nnet.binary_crossentropy(self.p_y_given_x, y))\n",
    "\n",
    "    def nll_multiclass(self, y):\n",
    "        # negative log likelihood based on multiclass cross entropy error\n",
    "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
    "        # number of time steps (call it T) in the sequence\n",
    "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
    "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
    "        # Log-Probabilities (call it LP) with one row per example and\n",
    "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
    "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
    "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
    "        # the mean (across minibatch examples) of the elements in v,\n",
    "        # i.e., the mean log-likelihood across the minibatch.\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "\n",
    "    def errors(self, y):\n",
    "        \"\"\"Return a float representing the number of errors in the sequence\n",
    "        over the total number of examples in the sequence ; zero one\n",
    "        loss over the size of the sequence\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "        \"\"\"\n",
    "        # check if y has same dimension of y_pred\n",
    "        if y.ndim != self.y_out.ndim:\n",
    "            raise TypeError('y should have the same shape as self.y_out',\n",
    "                ('y', y.type, 'y_out', self.y_out.type))\n",
    "\n",
    "        if self.output_type in ('binary', 'softmax'):\n",
    "            # check if y is of the correct datatype\n",
    "            if y.dtype.startswith('int'):\n",
    "                # the T.neq operator returns a vector of 0s and 1s, where 1\n",
    "                # represents a mistake in prediction\n",
    "                return T.mean(T.neq(self.y_out, y))\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "\n",
    "class MetaRNN(BaseEstimator):\n",
    "    def __init__(self, n_in=5, n_hidden=50, n_out=5, learning_rate=0.01,\n",
    "                 n_epochs=100, L1_reg=0.00, L2_reg=0.00, learning_rate_decay=1,\n",
    "                 activation='tanh', output_type='real',\n",
    "                 final_momentum=0.9, initial_momentum=0.5,\n",
    "                 momentum_switchover=5,\n",
    "                 use_symbolic_softmax=False):\n",
    "        self.n_in = int(n_in)\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.n_out = int(n_out)\n",
    "        self.learning_rate = float(learning_rate)\n",
    "        self.learning_rate_decay = float(learning_rate_decay)\n",
    "        self.n_epochs = int(n_epochs)\n",
    "        self.L1_reg = float(L1_reg)\n",
    "        self.L2_reg = float(L2_reg)\n",
    "        self.activation = activation\n",
    "        self.output_type = output_type\n",
    "        self.initial_momentum = float(initial_momentum)\n",
    "        self.final_momentum = float(final_momentum)\n",
    "        self.momentum_switchover = int(momentum_switchover)\n",
    "        self.use_symbolic_softmax = use_symbolic_softmax\n",
    "\n",
    "        self.ready()\n",
    "\n",
    "    def ready(self):\n",
    "        # input (where first dimension is time)\n",
    "        self.x = T.matrix()\n",
    "        # target (where first dimension is time)\n",
    "        if self.output_type == 'real':\n",
    "            self.y = T.matrix(name='y', dtype=theano.config.floatX)\n",
    "        elif self.output_type == 'binary':\n",
    "            self.y = T.matrix(name='y', dtype='int32')\n",
    "        elif self.output_type == 'softmax':  # only vector labels supported\n",
    "            self.y = T.vector(name='y', dtype='int32')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # initial hidden state of the RNN\n",
    "        self.h0 = T.vector()\n",
    "        # learning rate\n",
    "        self.lr = T.scalar()\n",
    "\n",
    "        if self.activation == 'tanh':\n",
    "            activation = T.tanh\n",
    "        elif self.activation == 'sigmoid':\n",
    "            activation = T.nnet.sigmoid\n",
    "        elif self.activation == 'relu':\n",
    "            activation = lambda x: x * (x > 0)\n",
    "        elif self.activation == 'cappedrelu':\n",
    "            activation = lambda x: T.minimum(x * (x > 0), 6)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.rnn = RNN(input=self.x, n_in=self.n_in,\n",
    "                       n_hidden=self.n_hidden, n_out=self.n_out,\n",
    "                       activation=activation, output_type=self.output_type,\n",
    "                       use_symbolic_softmax=self.use_symbolic_softmax)\n",
    "\n",
    "        if self.output_type == 'real':\n",
    "            self.predict = theano.function(inputs=[self.x, ],\n",
    "                                           outputs=self.rnn.y_pred,\n",
    "                                           mode=mode)\n",
    "        elif self.output_type == 'binary':\n",
    "            self.predict_proba = theano.function(inputs=[self.x, ],\n",
    "                                outputs=self.rnn.p_y_given_x, mode=mode)\n",
    "            self.predict = theano.function(inputs=[self.x, ],\n",
    "                                outputs=T.round(self.rnn.p_y_given_x),\n",
    "                                mode=mode)\n",
    "        elif self.output_type == 'softmax':\n",
    "            self.predict_proba = theano.function(inputs=[self.x, ],\n",
    "                        outputs=self.rnn.p_y_given_x, mode=mode)\n",
    "            self.predict = theano.function(inputs=[self.x, ],\n",
    "                                outputs=self.rnn.y_out, mode=mode)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def shared_dataset(self, data_xy):\n",
    "        \"\"\" Load the dataset into shared variables \"\"\"\n",
    "\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                            dtype=theano.config.floatX))\n",
    "\n",
    "        shared_y = theano.shared(np.asarray(data_y,\n",
    "                                            dtype=theano.config.floatX))\n",
    "\n",
    "        if self.output_type in ('binary', 'softmax'):\n",
    "            return shared_x, T.cast(shared_y, 'int32')\n",
    "        else:\n",
    "            return shared_x, shared_y\n",
    "\n",
    "    def __getstate__(self):\n",
    "        \"\"\" Return state sequence.\"\"\"\n",
    "        params = self._get_params()  # parameters set in constructor\n",
    "        weights = [p.get_value() for p in self.rnn.params]\n",
    "        state = (params, weights)\n",
    "        return state\n",
    "\n",
    "    def _set_weights(self, weights):\n",
    "        \"\"\" Set fittable parameters from weights sequence.\n",
    "        Parameters must be in the order defined by self.params:\n",
    "            W, W_in, W_out, h0, bh, by\n",
    "        \"\"\"\n",
    "        i = iter(weights)\n",
    "\n",
    "        for param in self.rnn.params:\n",
    "            param.set_value(i.next())\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        \"\"\" Set parameters from state sequence.\n",
    "        Parameters must be in the order defined by self.params:\n",
    "            W, W_in, W_out, h0, bh, by\n",
    "        \"\"\"\n",
    "        params, weights = state\n",
    "        self.set_params(**params)\n",
    "        self.ready()\n",
    "        self._set_weights(weights)\n",
    "\n",
    "    def save(self, fpath='.', fname=None):\n",
    "        \"\"\" Save a pickled representation of Model state. \"\"\"\n",
    "        fpathstart, fpathext = os.path.splitext(fpath)\n",
    "        if fpathext == '.pkl':\n",
    "            # User supplied an absolute path to a pickle file\n",
    "            fpath, fname = os.path.split(fpath)\n",
    "\n",
    "        elif fname is None:\n",
    "            # Generate filename based on date\n",
    "            date_obj = datetime.datetime.now()\n",
    "            date_str = date_obj.strftime('%Y-%m-%d-%H:%M:%S')\n",
    "            class_name = self.__class__.__name__\n",
    "            fname = '%s.%s.pkl' % (class_name, date_str)\n",
    "\n",
    "        fabspath = os.path.join(fpath, fname)\n",
    "\n",
    "        logger.info(\"Saving to %s ...\" % fabspath)\n",
    "        file = open(fabspath, 'wb')\n",
    "        state = self.__getstate__()\n",
    "        pickle.dump(state, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        file.close()\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\" Load model parameters from path. \"\"\"\n",
    "        logger.info(\"Loading from %s ...\" % path)\n",
    "        file = open(path, 'rb')\n",
    "        state = pickle.load(file)\n",
    "        self.__setstate__(state)\n",
    "        file.close()\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_test=None, Y_test=None,\n",
    "            validation_frequency=100):\n",
    "        \"\"\" Fit model\n",
    "        Pass in X_test, Y_test to compute test error and report during\n",
    "        training.\n",
    "        X_train : ndarray (n_seq x n_steps x n_in)\n",
    "        Y_train : ndarray (n_seq x n_steps x n_out)\n",
    "        validation_frequency : int\n",
    "            in terms of number of sequences (or number of weight updates)\n",
    "        \"\"\"\n",
    "        if X_test is not None:\n",
    "            assert(Y_test is not None)\n",
    "            self.interactive = True\n",
    "            test_set_x, test_set_y = self.shared_dataset((X_test, Y_test))\n",
    "        else:\n",
    "            self.interactive = False\n",
    "\n",
    "        train_set_x, train_set_y = self.shared_dataset((X_train, Y_train))\n",
    "\n",
    "        n_train = train_set_x.get_value(borrow=True).shape[0]\n",
    "        if self.interactive:\n",
    "            n_test = test_set_x.get_value(borrow=True).shape[0]\n",
    "\n",
    "        ######################\n",
    "        # BUILD ACTUAL MODEL #\n",
    "        ######################\n",
    "        logger.info('... building the model')\n",
    "\n",
    "        index = T.lscalar('index')    # index to a case\n",
    "        # learning rate (may change)\n",
    "        l_r = T.scalar('l_r', dtype=theano.config.floatX)\n",
    "        mom = T.scalar('mom', dtype=theano.config.floatX)  # momentum\n",
    "\n",
    "        cost = self.rnn.loss(self.y) \\\n",
    "            + self.L1_reg * self.rnn.L1 \\\n",
    "            + self.L2_reg * self.rnn.L2_sqr\n",
    "\n",
    "        compute_train_error = theano.function(inputs=[index, ],\n",
    "                                              outputs=self.rnn.loss(self.y),\n",
    "                                              givens={\n",
    "                                                  self.x: train_set_x[index],\n",
    "                                                  self.y: train_set_y[index]},\n",
    "            mode=mode)\n",
    "\n",
    "        if self.interactive:\n",
    "            compute_test_error = theano.function(inputs=[index, ],\n",
    "                        outputs=self.rnn.loss(self.y),\n",
    "                        givens={\n",
    "                            self.x: test_set_x[index],\n",
    "                            self.y: test_set_y[index]},\n",
    "                        mode=mode)\n",
    "\n",
    "        # compute the gradient of cost with respect to theta = (W, W_in, W_out)\n",
    "        # gradients on the weights using BPTT\n",
    "        gparams = []\n",
    "        for param in self.rnn.params:\n",
    "            gparam = T.grad(cost, param)\n",
    "            gparams.append(gparam)\n",
    "\n",
    "        updates = {}\n",
    "        for param, gparam in zip(self.rnn.params, gparams):\n",
    "            weight_update = self.rnn.updates[param]\n",
    "            upd = mom * weight_update - l_r * gparam\n",
    "            updates[weight_update] = upd\n",
    "            updates[param] = param + upd\n",
    "\n",
    "        # compiling a Theano function `train_model` that returns the\n",
    "        # cost, but in the same time updates the parameter of the\n",
    "        # model based on the rules defined in `updates`\n",
    "        train_model = theano.function(inputs=[index, l_r, mom],\n",
    "                                      outputs=cost,\n",
    "                                      updates=updates,\n",
    "                                      givens={\n",
    "                                          self.x: train_set_x[index],\n",
    "                                          self.y: train_set_y[index]},\n",
    "                                          mode=mode)\n",
    "\n",
    "        ###############\n",
    "        # TRAIN MODEL #\n",
    "        ###############\n",
    "        logger.info('... training')\n",
    "        epoch = 0\n",
    "\n",
    "        while (epoch < self.n_epochs):\n",
    "            epoch = epoch + 1\n",
    "            for idx in xrange(n_train):\n",
    "                effective_momentum = self.final_momentum \\\n",
    "                               if epoch > self.momentum_switchover \\\n",
    "                               else self.initial_momentum\n",
    "                example_cost = train_model(idx, self.learning_rate,\n",
    "                                           effective_momentum)\n",
    "\n",
    "                # iteration number (how many weight updates have we made?)\n",
    "                # epoch is 1-based, index is 0 based\n",
    "                iter = (epoch - 1) * n_train + idx + 1\n",
    "\n",
    "                if iter % validation_frequency == 0:\n",
    "                    # compute loss on training set\n",
    "                    train_losses = [compute_train_error(i)\n",
    "                                    for i in xrange(n_train)]\n",
    "                    this_train_loss = np.mean(train_losses)\n",
    "\n",
    "                    if self.interactive:\n",
    "                        test_losses = [compute_test_error(i)\n",
    "                                        for i in xrange(n_test)]\n",
    "                        this_test_loss = np.mean(test_losses)\n",
    "\n",
    "                        logger.info('epoch %i, seq %i/%i, tr loss %f '\n",
    "                                    'te loss %f lr: %f' % \\\n",
    "                        (epoch, idx + 1, n_train,\n",
    "                         this_train_loss, this_test_loss, self.learning_rate))\n",
    "                    else:\n",
    "                        logger.info('epoch %i, seq %i/%i, train loss %f '\n",
    "                                    'lr: %f' % \\\n",
    "                                    (epoch, idx + 1, n_train, this_train_loss,\n",
    "                                     self.learning_rate))\n",
    "\n",
    "            self.learning_rate *= self.learning_rate_decay\n",
    "\n",
    "\n",
    "def test_real():\n",
    "    \"\"\" Test RNN with real-valued outputs. \"\"\"\n",
    "    n_hidden = 10\n",
    "    n_in = 5\n",
    "    n_out = 3\n",
    "    n_steps = 10\n",
    "    n_seq = 100\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # simple lag test\n",
    "    seq = np.random.randn(n_seq, n_steps, n_in)\n",
    "    targets = np.zeros((n_seq, n_steps, n_out))\n",
    "\n",
    "    targets[:, 1:, 0] = seq[:, :-1, 3]  # delayed 1\n",
    "    targets[:, 1:, 1] = seq[:, :-1, 2]  # delayed 1\n",
    "    targets[:, 2:, 2] = seq[:, :-2, 0]  # delayed 2\n",
    "\n",
    "    targets += 0.01 * np.random.standard_normal(targets.shape)\n",
    "\n",
    "    model = MetaRNN(n_in=n_in, n_hidden=n_hidden, n_out=n_out,\n",
    "                    learning_rate=0.001, learning_rate_decay=0.999,\n",
    "                    n_epochs=400, activation='tanh')\n",
    "\n",
    "    model.fit(seq, targets, validation_frequency=1000)\n",
    "\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot(211)\n",
    "    plt.plot(seq[0])\n",
    "    ax1.set_title('input')\n",
    "\n",
    "    ax2 = plt.subplot(212)\n",
    "    true_targets = plt.plot(targets[0])\n",
    "\n",
    "    guess = model.predict(seq[0])\n",
    "    guessed_targets = plt.plot(guess, linestyle='--')\n",
    "    for i, x in enumerate(guessed_targets):\n",
    "        x.set_color(true_targets[i].get_color())\n",
    "    ax2.set_title('solid: true output, dashed: model output')\n",
    "\n",
    "\n",
    "def test_binary(multiple_out=False, n_epochs=250):\n",
    "    \"\"\" Test RNN with binary outputs. \"\"\"\n",
    "    n_hidden = 10\n",
    "    n_in = 5\n",
    "    if multiple_out:\n",
    "        n_out = 2\n",
    "    else:\n",
    "        n_out = 1\n",
    "    n_steps = 10\n",
    "    n_seq = 100\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # simple lag test\n",
    "    seq = np.random.randn(n_seq, n_steps, n_in)\n",
    "    targets = np.zeros((n_seq, n_steps, n_out))\n",
    "\n",
    "    # whether lag 1 (dim 3) is greater than lag 2 (dim 0)\n",
    "    targets[:, 2:, 0] = np.cast[np.int](seq[:, 1:-1, 3] > seq[:, :-2, 0])\n",
    "\n",
    "    if multiple_out:\n",
    "        # whether product of lag 1 (dim 4) and lag 1 (dim 2)\n",
    "        # is less than lag 2 (dim 0)\n",
    "        targets[:, 2:, 1] = np.cast[np.int](\n",
    "            (seq[:, 1:-1, 4] * seq[:, 1:-1, 2]) > seq[:, :-2, 0])\n",
    "\n",
    "    model = MetaRNN(n_in=n_in, n_hidden=n_hidden, n_out=n_out,\n",
    "                    learning_rate=0.001, learning_rate_decay=0.999,\n",
    "                    n_epochs=n_epochs, activation='tanh', output_type='binary')\n",
    "\n",
    "    model.fit(seq, targets, validation_frequency=1000)\n",
    "\n",
    "    seqs = xrange(10)\n",
    "\n",
    "    plt.close('all')\n",
    "    for seq_num in seqs:\n",
    "        fig = plt.figure()\n",
    "        ax1 = plt.subplot(211)\n",
    "        plt.plot(seq[seq_num])\n",
    "        ax1.set_title('input')\n",
    "        ax2 = plt.subplot(212)\n",
    "        true_targets = plt.step(xrange(n_steps), targets[seq_num], marker='o')\n",
    "\n",
    "        guess = model.predict_proba(seq[seq_num])\n",
    "        guessed_targets = plt.step(xrange(n_steps), guess)\n",
    "        plt.setp(guessed_targets, linestyle='--', marker='d')\n",
    "        for i, x in enumerate(guessed_targets):\n",
    "            x.set_color(true_targets[i].get_color())\n",
    "        ax2.set_ylim((-0.1, 1.1))\n",
    "        ax2.set_title('solid: true output, dashed: model output (prob)')\n",
    "\n",
    "\n",
    "def test_softmax(n_epochs=250):\n",
    "    \"\"\" Test RNN with softmax outputs. \"\"\"\n",
    "    n_hidden = 10\n",
    "    n_in = 5\n",
    "    n_steps = 10\n",
    "    n_seq = 100\n",
    "    n_classes = 3\n",
    "    n_out = n_classes  # restricted to single softmax per time step\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # simple lag test\n",
    "    seq = np.random.randn(n_seq, n_steps, n_in)\n",
    "    targets = np.zeros((n_seq, n_steps), dtype=np.int)\n",
    "\n",
    "    thresh = 0.5\n",
    "    # if lag 1 (dim 3) is greater than lag 2 (dim 0) + thresh\n",
    "    # class 1\n",
    "    # if lag 1 (dim 3) is less than lag 2 (dim 0) - thresh\n",
    "    # class 2\n",
    "    # if lag 2(dim0) - thresh <= lag 1 (dim 3) <= lag2(dim0) + thresh\n",
    "    # class 0\n",
    "    targets[:, 2:][seq[:, 1:-1, 3] > seq[:, :-2, 0] + thresh] = 1\n",
    "    targets[:, 2:][seq[:, 1:-1, 3] < seq[:, :-2, 0] - thresh] = 2\n",
    "    #targets[:, 2:, 0] = np.cast[np.int](seq[:, 1:-1, 3] > seq[:, :-2, 0])\n",
    "\n",
    "    model = MetaRNN(n_in=n_in, n_hidden=n_hidden, n_out=n_out,\n",
    "                    learning_rate=0.001, learning_rate_decay=0.999,\n",
    "                    n_epochs=n_epochs, activation='tanh',\n",
    "                    output_type='softmax', use_symbolic_softmax=False)\n",
    "\n",
    "    model.fit(seq, targets, validation_frequency=1000)\n",
    "\n",
    "    seqs = xrange(10)\n",
    "\n",
    "    plt.close('all')\n",
    "    for seq_num in seqs:\n",
    "        fig = plt.figure()\n",
    "        ax1 = plt.subplot(211)\n",
    "        plt.plot(seq[seq_num])\n",
    "        ax1.set_title('input')\n",
    "        ax2 = plt.subplot(212)\n",
    "\n",
    "        # blue line will represent true classes\n",
    "        true_targets = plt.step(xrange(n_steps), targets[seq_num], marker='o')\n",
    "\n",
    "        # show probabilities (in b/w) output by model\n",
    "        guess = model.predict_proba(seq[seq_num])\n",
    "        guessed_probs = plt.imshow(guess.T, interpolation='nearest',\n",
    "                                   cmap='gray')\n",
    "        ax2.set_title('blue: true class, grayscale: probs assigned by model')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    t0 = time.time()\n",
    "    test_real()\n",
    "    # problem takes more epochs to solve\n",
    "    #test_binary(multiple_out=True, n_epochs=2400)\n",
    "    #test_softmax(n_epochs=250)\n",
    "    print \"Elapsed time: %f\" % (time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:51: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <type 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (theano.compat.python2x.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n",
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '7604' (I am process '7668')\n",
      "WARNING:theano.gof.compilelock:Overriding existing lock by dead process '7604' (I am process '7668')\n",
      "D:\\Anaconda\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as TT\n",
    "\n",
    "# number of hidden units\n",
    "n = 50\n",
    "# number of input units\n",
    "nin = 5\n",
    "# number of output units\n",
    "nout = 5\n",
    "\n",
    "# input (where first dimension is time)\n",
    "u = TT.matrix()\n",
    "# target (where first dimension is time)\n",
    "t = TT.matrix()\n",
    "# initial hidden state of the RNN\n",
    "h0 = TT.vector()\n",
    "# learning rate\n",
    "lr = TT.scalar()\n",
    "# recurrent weights as a shared variable\n",
    "W = theano.shared(numpy.random.uniform(size=(n, n), low=-.01, high=.01))\n",
    "# input to hidden layer weights\n",
    "W_in = theano.shared(numpy.random.uniform(size=(nin, n), low=-.01, high=.01))\n",
    "# hidden to output layer weights\n",
    "W_out = theano.shared(numpy.random.uniform(size=(n, nout), low=-.01, high=.01))\n",
    "\n",
    "\n",
    "# recurrent function (using tanh activation function) and linear output\n",
    "# activation function\n",
    "def step(u_t, h_tm1, W, W_in, W_out):\n",
    "    h_t = TT.tanh(TT.dot(u_t, W_in) + TT.dot(h_tm1, W))\n",
    "    y_t = TT.dot(h_t, W_out)\n",
    "    return h_t, y_t\n",
    "\n",
    "# the hidden state `h` for the entire sequence, and the output for the\n",
    "# entrie sequence `y` (first dimension is always time)\n",
    "[h, y], _ = theano.scan(step,\n",
    "                        sequences=u,\n",
    "                        outputs_info=[h0, None],\n",
    "                        non_sequences=[W, W_in, W_out])\n",
    "# error between output and target\n",
    "error = ((y - t) ** 2).sum()\n",
    "# gradients on the weights using BPTT\n",
    "gW, gW_in, gW_out = TT.grad(error, [W, W_in, W_out])\n",
    "# training function, that computes the error and updates the weights using\n",
    "# SGD.\n",
    "fn = theano.function([h0, u, t, lr],\n",
    "                     error,\n",
    "                     updates={W: W - lr * gW,\n",
    "                             W_in: W_in - lr * gW_in,\n",
    "                             W_out: W_out - lr * gW_out})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
