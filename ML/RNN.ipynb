{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.pkl\n",
      "33218560/33213513 [==============================] - 734s   \n",
      "20000 train sequences\n",
      "5000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (20000L, 100L)\n",
      "X_test shape: (5000L, 100L)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 0\n",
      "20000/20000 [==============================] - 389s - loss: 0.4851 - acc: 0.7706 - val_loss: 0.4039 - val_acc: 0.8222\n",
      "Epoch 1\n",
      "20000/20000 [==============================] - 382s - loss: 0.2723 - acc: 0.8907 - val_loss: 0.3760 - val_acc: 0.8320\n",
      "Epoch 2\n",
      "20000/20000 [==============================] - 528s - loss: 0.1746 - acc: 0.9366 - val_loss: 0.3890 - val_acc: 0.8316\n",
      "Epoch 3\n",
      "20000/20000 [==============================] - 585s - loss: 0.1036 - acc: 0.9651 - val_loss: 0.4854 - val_acc: 0.8380\n",
      "5000/5000 [==============================] - 28s    \n",
      "Test score: 0.485364478692\n",
      "Test accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "'''\n",
    "    Train a LSTM on the IMDB sentiment classification task.\n",
    "    The dataset is actually too small for LSTM to be of any advantage\n",
    "    compared to simpler, much faster methods such as TF-IDF+LogReg.\n",
    "    Notes:\n",
    "    - RNNs are tricky. Choice of batch size is important,\n",
    "    choice of loss and optimizer is critical, etc.\n",
    "    Some configurations won't converge.\n",
    "    - LSTM loss decrease patterns during training can be quite different\n",
    "    from what you see with CNNs/MLPs/etc.\n",
    "    GPU command:\n",
    "        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py\n",
    "'''\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, 128))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=4, validation_data=(X_test, y_test), show_accuracy=True)\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-4b330ea9ad5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, class_mode, theano_mode)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\layers\\containers.pyc\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\layers\\core.pyc\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\layers\\core.pyc\u001b[0m in \u001b[0;36mget_input\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'previous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\layers\\core.pyc\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\layers\\core.pyc\u001b[0m in \u001b[0;36mget_input\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'previous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\layers\\recurrent.pyc\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m    173\u001b[0m             )],\n\u001b[0;32m    174\u001b[0m             \u001b[0mnon_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mtruncate_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncate_gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         )\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\scan_module\\scan.pyc\u001b[0m in \u001b[0;36mscan\u001b[1;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict)\u001b[0m\n\u001b[0;32m    814\u001b[0m                                               optimizer=None),\n\u001b[0;32m    815\u001b[0m                        \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m                        profile=False)\n\u001b[0m\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[0;32m   1463\u001b[0m                    \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m                        defaults)\n\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph)\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[1;31m# 3) This helps propagate knowledge of newly compiled modules to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;31m#    concurrent processes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_module_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[1;31m# Handle the case where inputs and/or outputs is a single\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;31m# Variable (not in a list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\theano\\gof\\cmodule.pyc\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self, age_thresh_use, delete_if_problem, cleanup)\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m                 \u001b[1;31m# Test to see that the file is [present and] readable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m                 \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m                 \u001b[0mgone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleDeepRNN\n",
    "\n",
    "mean, std = 0,15\n",
    "X, Y = [], []\n",
    "for i in range(300):\n",
    "    seq = np.array(np.random.normal(mean, std, 20),dtype=int)\n",
    "    \n",
    "    label = np.random.randint(2)\n",
    "    if label==0: seq *= -1\n",
    "\n",
    "    X.append(sorted(seq))\n",
    "    Y.append(label)\n",
    "\n",
    "X_train, Y_train = X[:200], Y[:200]\n",
    "X_test, Y_test = X[200:], Y[200:]\n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "# model.add(Embedding(15, 5))\n",
    "model.add(SimpleDeepRNN(20,5, activation='sigmoid', inner_activation='hard_sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(5, 2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=4, nb_epoch=4)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "TypeError while preparing batch.                         If using HDF5 input data, pass shuffle=\"batch\".\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer arrays with one element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-d0ae6ece2120>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    488\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mbatch_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                     print('TypeError while preparing batch. \\\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mslice_X\u001b[1;34m(X, start, stop)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer arrays with one element can be converted to an index"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "X_test, Y_test = [],[]\n",
    "\n",
    "mean, std = 0,15\n",
    "X, Y = [], []\n",
    "for i in range(300):\n",
    "    seq = np.random.normal(mean, std, 20)\n",
    "    \n",
    "    label = np.random.randint(2)\n",
    "    if label==0: seq *= -1\n",
    "\n",
    "    X.append(sorted(seq))\n",
    "    Y.append(label)\n",
    "\n",
    "X_train, Y_train = X[:200], Y[:200]\n",
    "X_test, Y_test = X[200:], Y[200:]\n",
    "    \n",
    "model.fit(X_train, Y_train, batch_size=4, nb_epoch=4)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['step']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "D:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:398: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <type 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (theano.compat.python2x.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Elapsed time: 109.829000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEKCAYAAAALoA6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXKPRaHIo/w+MbzPDnBM8UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f52c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Vanilla RNN\n",
    "@author Graham Taylor\n",
    "\"\"\"\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.base import BaseEstimator\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import cPickle as pickle\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "mode = theano.Mode(linker='cvm')\n",
    "#mode = 'DEBUG_MODE'\n",
    "\n",
    "\n",
    "class RNN(object):\n",
    "    \"\"\"    Recurrent neural network class\n",
    "    Supported output types:\n",
    "    real : linear output units, use mean-squared error\n",
    "    binary : binary output units, use cross-entropy error\n",
    "    softmax : single softmax out, use cross-entropy error\n",
    "    \"\"\"\n",
    "    def __init__(self, input, n_in, n_hidden, n_out, activation=T.tanh,\n",
    "                 output_type='real', use_symbolic_softmax=False):\n",
    "\n",
    "        self.input = input\n",
    "        self.activation = activation\n",
    "        self.output_type = output_type\n",
    "\n",
    "        # when using HF, SoftmaxGrad.grad is not implemented\n",
    "        # use a symbolic softmax which is slightly slower than T.nnet.softmax\n",
    "        # See: http://groups.google.com/group/theano-dev/browse_thread/\n",
    "        # thread/3930bd5a6a67d27a\n",
    "        if use_symbolic_softmax:\n",
    "            def symbolic_softmax(x):\n",
    "                e = T.exp(x)\n",
    "                return e / T.sum(e, axis=1).dimshuffle(0, 'x')\n",
    "            self.softmax = symbolic_softmax\n",
    "        else:\n",
    "            self.softmax = T.nnet.softmax\n",
    "\n",
    "        # recurrent weights as a shared variable\n",
    "        W_init = np.asarray(np.random.uniform(size=(n_hidden, n_hidden),\n",
    "                                              low=-.01, high=.01),\n",
    "                                              dtype=theano.config.floatX)\n",
    "        self.W = theano.shared(value=W_init, name='W')\n",
    "        # input to hidden layer weights\n",
    "        W_in_init = np.asarray(np.random.uniform(size=(n_in, n_hidden),\n",
    "                                                 low=-.01, high=.01),\n",
    "                                                 dtype=theano.config.floatX)\n",
    "        self.W_in = theano.shared(value=W_in_init, name='W_in')\n",
    "\n",
    "        # hidden to output layer weights\n",
    "        W_out_init = np.asarray(np.random.uniform(size=(n_hidden, n_out),\n",
    "                                                  low=-.01, high=.01),\n",
    "                                                  dtype=theano.config.floatX)\n",
    "        self.W_out = theano.shared(value=W_out_init, name='W_out')\n",
    "\n",
    "        h0_init = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        self.h0 = theano.shared(value=h0_init, name='h0')\n",
    "\n",
    "        bh_init = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        self.bh = theano.shared(value=bh_init, name='bh')\n",
    "\n",
    "        by_init = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "        self.by = theano.shared(value=by_init, name='by')\n",
    "\n",
    "        self.params = [self.W, self.W_in, self.W_out, self.h0,\n",
    "                       self.bh, self.by]\n",
    "\n",
    "        # for every parameter, we maintain it's last update\n",
    "        # the idea here is to use \"momentum\"\n",
    "        # keep moving mostly in the same direction\n",
    "        self.updates = {}\n",
    "        for param in self.params:\n",
    "            init = np.zeros(param.get_value(borrow=True).shape,\n",
    "                            dtype=theano.config.floatX)\n",
    "            self.updates[param] = theano.shared(init)\n",
    "\n",
    "        # recurrent function (using tanh activation function) and linear output\n",
    "        # activation function\n",
    "        def step(x_t, h_tm1):\n",
    "            h_t = self.activation(T.dot(x_t, self.W_in) + \\\n",
    "                                  T.dot(h_tm1, self.W) + self.bh)\n",
    "            y_t = T.dot(h_t, self.W_out) + self.by\n",
    "            return h_t, y_t\n",
    "\n",
    "        # the hidden state `h` for the entire sequence, and the output for the\n",
    "        # entire sequence `y` (first dimension is always time)\n",
    "        [self.h, self.y_pred], _ = theano.scan(step,\n",
    "                                               sequences=self.input,\n",
    "                                               outputs_info=[self.h0, None])\n",
    "\n",
    "        # L1 norm ; one regularization option is to enforce L1 norm to\n",
    "        # be small\n",
    "        self.L1 = 0\n",
    "        self.L1 += abs(self.W.sum())\n",
    "        self.L1 += abs(self.W_in.sum())\n",
    "        self.L1 += abs(self.W_out.sum())\n",
    "\n",
    "        # square of L2 norm ; one regularization option is to enforce\n",
    "        # square of L2 norm to be small\n",
    "        self.L2_sqr = 0\n",
    "        self.L2_sqr += (self.W ** 2).sum()\n",
    "        self.L2_sqr += (self.W_in ** 2).sum()\n",
    "        self.L2_sqr += (self.W_out ** 2).sum()\n",
    "\n",
    "        if self.output_type == 'real':\n",
    "            self.loss = lambda y: self.mse(y)\n",
    "        elif self.output_type == 'binary':\n",
    "            # push through sigmoid\n",
    "            self.p_y_given_x = T.nnet.sigmoid(self.y_pred)  # apply sigmoid\n",
    "            self.y_out = T.round(self.p_y_given_x)  # round to {0,1}\n",
    "            self.loss = lambda y: self.nll_binary(y)\n",
    "        elif self.output_type == 'softmax':\n",
    "            # push through softmax, computing vector of class-membership\n",
    "            # probabilities in symbolic form\n",
    "            self.p_y_given_x = self.softmax(self.y_pred)\n",
    "\n",
    "            # compute prediction as class whose probability is maximal\n",
    "            self.y_out = T.argmax(self.p_y_given_x, axis=-1)\n",
    "            self.loss = lambda y: self.nll_multiclass(y)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def mse(self, y):\n",
    "        # error between output and target\n",
    "        return T.mean((self.y_pred - y) ** 2)\n",
    "\n",
    "    def nll_binary(self, y):\n",
    "        # negative log likelihood based on binary cross entropy error\n",
    "        return T.mean(T.nnet.binary_crossentropy(self.p_y_given_x, y))\n",
    "\n",
    "    def nll_multiclass(self, y):\n",
    "        # negative log likelihood based on multiclass cross entropy error\n",
    "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
    "        # number of time steps (call it T) in the sequence\n",
    "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
    "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
    "        # Log-Probabilities (call it LP) with one row per example and\n",
    "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
    "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
    "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
    "        # the mean (across minibatch examples) of the elements in v,\n",
    "        # i.e., the mean log-likelihood across the minibatch.\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "\n",
    "    def errors(self, y):\n",
    "        \"\"\"Return a float representing the number of errors in the sequence\n",
    "        over the total number of examples in the sequence ; zero one\n",
    "        loss over the size of the sequence\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "        \"\"\"\n",
    "        # check if y has same dimension of y_pred\n",
    "        if y.ndim != self.y_out.ndim:\n",
    "            raise TypeError('y should have the same shape as self.y_out',\n",
    "                ('y', y.type, 'y_out', self.y_out.type))\n",
    "\n",
    "        if self.output_type in ('binary', 'softmax'):\n",
    "            # check if y is of the correct datatype\n",
    "            if y.dtype.startswith('int'):\n",
    "                # the T.neq operator returns a vector of 0s and 1s, where 1\n",
    "                # represents a mistake in prediction\n",
    "                return T.mean(T.neq(self.y_out, y))\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "\n",
    "class MetaRNN(BaseEstimator):\n",
    "    def __init__(self, n_in=5, n_hidden=50, n_out=5, learning_rate=0.01,\n",
    "                 n_epochs=100, L1_reg=0.00, L2_reg=0.00, learning_rate_decay=1,\n",
    "                 activation='tanh', output_type='real',\n",
    "                 final_momentum=0.9, initial_momentum=0.5,\n",
    "                 momentum_switchover=5,\n",
    "                 use_symbolic_softmax=False):\n",
    "        self.n_in = int(n_in)\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.n_out = int(n_out)\n",
    "        self.learning_rate = float(learning_rate)\n",
    "        self.learning_rate_decay = float(learning_rate_decay)\n",
    "        self.n_epochs = int(n_epochs)\n",
    "        self.L1_reg = float(L1_reg)\n",
    "        self.L2_reg = float(L2_reg)\n",
    "        self.activation = activation\n",
    "        self.output_type = output_type\n",
    "        self.initial_momentum = float(initial_momentum)\n",
    "        self.final_momentum = float(final_momentum)\n",
    "        self.momentum_switchover = int(momentum_switchover)\n",
    "        self.use_symbolic_softmax = use_symbolic_softmax\n",
    "\n",
    "        self.ready()\n",
    "\n",
    "    def ready(self):\n",
    "        # input (where first dimension is time)\n",
    "        self.x = T.matrix()\n",
    "        # target (where first dimension is time)\n",
    "        if self.output_type == 'real':\n",
    "            self.y = T.matrix(name='y', dtype=theano.config.floatX)\n",
    "        elif self.output_type == 'binary':\n",
    "            self.y = T.matrix(name='y', dtype='int32')\n",
    "        elif self.output_type == 'softmax':  # only vector labels supported\n",
    "            self.y = T.vector(name='y', dtype='int32')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # initial hidden state of the RNN\n",
    "        self.h0 = T.vector()\n",
    "        # learning rate\n",
    "        self.lr = T.scalar()\n",
    "\n",
    "        if self.activation == 'tanh':\n",
    "            activation = T.tanh\n",
    "        elif self.activation == 'sigmoid':\n",
    "            activation = T.nnet.sigmoid\n",
    "        elif self.activation == 'relu':\n",
    "            activation = lambda x: x * (x > 0)\n",
    "        elif self.activation == 'cappedrelu':\n",
    "            activation = lambda x: T.minimum(x * (x > 0), 6)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.rnn = RNN(input=self.x, n_in=self.n_in,\n",
    "                       n_hidden=self.n_hidden, n_out=self.n_out,\n",
    "                       activation=activation, output_type=self.output_type,\n",
    "                       use_symbolic_softmax=self.use_symbolic_softmax)\n",
    "\n",
    "        if self.output_type == 'real':\n",
    "            self.predict = theano.function(inputs=[self.x, ],\n",
    "                                           outputs=self.rnn.y_pred,\n",
    "                                           mode=mode)\n",
    "        elif self.output_type == 'binary':\n",
    "            self.predict_proba = theano.function(inputs=[self.x, ],\n",
    "                                outputs=self.rnn.p_y_given_x, mode=mode)\n",
    "            self.predict = theano.function(inputs=[self.x, ],\n",
    "                                outputs=T.round(self.rnn.p_y_given_x),\n",
    "                                mode=mode)\n",
    "        elif self.output_type == 'softmax':\n",
    "            self.predict_proba = theano.function(inputs=[self.x, ],\n",
    "                        outputs=self.rnn.p_y_given_x, mode=mode)\n",
    "            self.predict = theano.function(inputs=[self.x, ],\n",
    "                                outputs=self.rnn.y_out, mode=mode)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def shared_dataset(self, data_xy):\n",
    "        \"\"\" Load the dataset into shared variables \"\"\"\n",
    "\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                            dtype=theano.config.floatX))\n",
    "\n",
    "        shared_y = theano.shared(np.asarray(data_y,\n",
    "                                            dtype=theano.config.floatX))\n",
    "\n",
    "        if self.output_type in ('binary', 'softmax'):\n",
    "            return shared_x, T.cast(shared_y, 'int32')\n",
    "        else:\n",
    "            return shared_x, shared_y\n",
    "\n",
    "    def __getstate__(self):\n",
    "        \"\"\" Return state sequence.\"\"\"\n",
    "        params = self._get_params()  # parameters set in constructor\n",
    "        weights = [p.get_value() for p in self.rnn.params]\n",
    "        state = (params, weights)\n",
    "        return state\n",
    "\n",
    "    def _set_weights(self, weights):\n",
    "        \"\"\" Set fittable parameters from weights sequence.\n",
    "        Parameters must be in the order defined by self.params:\n",
    "            W, W_in, W_out, h0, bh, by\n",
    "        \"\"\"\n",
    "        i = iter(weights)\n",
    "\n",
    "        for param in self.rnn.params:\n",
    "            param.set_value(i.next())\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        \"\"\" Set parameters from state sequence.\n",
    "        Parameters must be in the order defined by self.params:\n",
    "            W, W_in, W_out, h0, bh, by\n",
    "        \"\"\"\n",
    "        params, weights = state\n",
    "        self.set_params(**params)\n",
    "        self.ready()\n",
    "        self._set_weights(weights)\n",
    "\n",
    "    def save(self, fpath='.', fname=None):\n",
    "        \"\"\" Save a pickled representation of Model state. \"\"\"\n",
    "        fpathstart, fpathext = os.path.splitext(fpath)\n",
    "        if fpathext == '.pkl':\n",
    "            # User supplied an absolute path to a pickle file\n",
    "            fpath, fname = os.path.split(fpath)\n",
    "\n",
    "        elif fname is None:\n",
    "            # Generate filename based on date\n",
    "            date_obj = datetime.datetime.now()\n",
    "            date_str = date_obj.strftime('%Y-%m-%d-%H:%M:%S')\n",
    "            class_name = self.__class__.__name__\n",
    "            fname = '%s.%s.pkl' % (class_name, date_str)\n",
    "\n",
    "        fabspath = os.path.join(fpath, fname)\n",
    "\n",
    "        logger.info(\"Saving to %s ...\" % fabspath)\n",
    "        file = open(fabspath, 'wb')\n",
    "        state = self.__getstate__()\n",
    "        pickle.dump(state, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        file.close()\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\" Load model parameters from path. \"\"\"\n",
    "        logger.info(\"Loading from %s ...\" % path)\n",
    "        file = open(path, 'rb')\n",
    "        state = pickle.load(file)\n",
    "        self.__setstate__(state)\n",
    "        file.close()\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_test=None, Y_test=None,\n",
    "            validation_frequency=100):\n",
    "        \"\"\" Fit model\n",
    "        Pass in X_test, Y_test to compute test error and report during\n",
    "        training.\n",
    "        X_train : ndarray (n_seq x n_steps x n_in)\n",
    "        Y_train : ndarray (n_seq x n_steps x n_out)\n",
    "        validation_frequency : int\n",
    "            in terms of number of sequences (or number of weight updates)\n",
    "        \"\"\"\n",
    "        if X_test is not None:\n",
    "            assert(Y_test is not None)\n",
    "            self.interactive = True\n",
    "            test_set_x, test_set_y = self.shared_dataset((X_test, Y_test))\n",
    "        else:\n",
    "            self.interactive = False\n",
    "\n",
    "        train_set_x, train_set_y = self.shared_dataset((X_train, Y_train))\n",
    "\n",
    "        n_train = train_set_x.get_value(borrow=True).shape[0]\n",
    "        if self.interactive:\n",
    "            n_test = test_set_x.get_value(borrow=True).shape[0]\n",
    "\n",
    "        ######################\n",
    "        # BUILD ACTUAL MODEL #\n",
    "        ######################\n",
    "        logger.info('... building the model')\n",
    "\n",
    "        index = T.lscalar('index')    # index to a case\n",
    "        # learning rate (may change)\n",
    "        l_r = T.scalar('l_r', dtype=theano.config.floatX)\n",
    "        mom = T.scalar('mom', dtype=theano.config.floatX)  # momentum\n",
    "\n",
    "        cost = self.rnn.loss(self.y) \\\n",
    "            + self.L1_reg * self.rnn.L1 \\\n",
    "            + self.L2_reg * self.rnn.L2_sqr\n",
    "\n",
    "        compute_train_error = theano.function(inputs=[index, ],\n",
    "                                              outputs=self.rnn.loss(self.y),\n",
    "                                              givens={\n",
    "                                                  self.x: train_set_x[index],\n",
    "                                                  self.y: train_set_y[index]},\n",
    "            mode=mode)\n",
    "\n",
    "        if self.interactive:\n",
    "            compute_test_error = theano.function(inputs=[index, ],\n",
    "                        outputs=self.rnn.loss(self.y),\n",
    "                        givens={\n",
    "                            self.x: test_set_x[index],\n",
    "                            self.y: test_set_y[index]},\n",
    "                        mode=mode)\n",
    "\n",
    "        # compute the gradient of cost with respect to theta = (W, W_in, W_out)\n",
    "        # gradients on the weights using BPTT\n",
    "        gparams = []\n",
    "        for param in self.rnn.params:\n",
    "            gparam = T.grad(cost, param)\n",
    "            gparams.append(gparam)\n",
    "\n",
    "        updates = {}\n",
    "        for param, gparam in zip(self.rnn.params, gparams):\n",
    "            weight_update = self.rnn.updates[param]\n",
    "            upd = mom * weight_update - l_r * gparam\n",
    "            updates[weight_update] = upd\n",
    "            updates[param] = param + upd\n",
    "\n",
    "        # compiling a Theano function `train_model` that returns the\n",
    "        # cost, but in the same time updates the parameter of the\n",
    "        # model based on the rules defined in `updates`\n",
    "        train_model = theano.function(inputs=[index, l_r, mom],\n",
    "                                      outputs=cost,\n",
    "                                      updates=updates,\n",
    "                                      givens={\n",
    "                                          self.x: train_set_x[index],\n",
    "                                          self.y: train_set_y[index]},\n",
    "                                          mode=mode)\n",
    "\n",
    "        ###############\n",
    "        # TRAIN MODEL #\n",
    "        ###############\n",
    "        logger.info('... training')\n",
    "        epoch = 0\n",
    "\n",
    "        while (epoch < self.n_epochs):\n",
    "            epoch = epoch + 1\n",
    "            for idx in xrange(n_train):\n",
    "                effective_momentum = self.final_momentum \\\n",
    "                               if epoch > self.momentum_switchover \\\n",
    "                               else self.initial_momentum\n",
    "                example_cost = train_model(idx, self.learning_rate,\n",
    "                                           effective_momentum)\n",
    "\n",
    "                # iteration number (how many weight updates have we made?)\n",
    "                # epoch is 1-based, index is 0 based\n",
    "                iter = (epoch - 1) * n_train + idx + 1\n",
    "\n",
    "                if iter % validation_frequency == 0:\n",
    "                    # compute loss on training set\n",
    "                    train_losses = [compute_train_error(i)\n",
    "                                    for i in xrange(n_train)]\n",
    "                    this_train_loss = np.mean(train_losses)\n",
    "\n",
    "                    if self.interactive:\n",
    "                        test_losses = [compute_test_error(i)\n",
    "                                        for i in xrange(n_test)]\n",
    "                        this_test_loss = np.mean(test_losses)\n",
    "\n",
    "                        logger.info('epoch %i, seq %i/%i, tr loss %f '\n",
    "                                    'te loss %f lr: %f' % \\\n",
    "                        (epoch, idx + 1, n_train,\n",
    "                         this_train_loss, this_test_loss, self.learning_rate))\n",
    "                    else:\n",
    "                        logger.info('epoch %i, seq %i/%i, train loss %f '\n",
    "                                    'lr: %f' % \\\n",
    "                                    (epoch, idx + 1, n_train, this_train_loss,\n",
    "                                     self.learning_rate))\n",
    "\n",
    "            self.learning_rate *= self.learning_rate_decay\n",
    "\n",
    "\n",
    "def test_real():\n",
    "    \"\"\" Test RNN with real-valued outputs. \"\"\"\n",
    "    n_hidden = 10\n",
    "    n_in = 5\n",
    "    n_out = 3\n",
    "    n_steps = 10\n",
    "    n_seq = 100\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # simple lag test\n",
    "    seq = np.random.randn(n_seq, n_steps, n_in)\n",
    "    targets = np.zeros((n_seq, n_steps, n_out))\n",
    "\n",
    "    targets[:, 1:, 0] = seq[:, :-1, 3]  # delayed 1\n",
    "    targets[:, 1:, 1] = seq[:, :-1, 2]  # delayed 1\n",
    "    targets[:, 2:, 2] = seq[:, :-2, 0]  # delayed 2\n",
    "\n",
    "    targets += 0.01 * np.random.standard_normal(targets.shape)\n",
    "\n",
    "    model = MetaRNN(n_in=n_in, n_hidden=n_hidden, n_out=n_out,\n",
    "                    learning_rate=0.001, learning_rate_decay=0.999,\n",
    "                    n_epochs=400, activation='tanh')\n",
    "\n",
    "    model.fit(seq, targets, validation_frequency=1000)\n",
    "\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot(211)\n",
    "    plt.plot(seq[0])\n",
    "    ax1.set_title('input')\n",
    "\n",
    "    ax2 = plt.subplot(212)\n",
    "    true_targets = plt.plot(targets[0])\n",
    "\n",
    "    guess = model.predict(seq[0])\n",
    "    guessed_targets = plt.plot(guess, linestyle='--')\n",
    "    for i, x in enumerate(guessed_targets):\n",
    "        x.set_color(true_targets[i].get_color())\n",
    "    ax2.set_title('solid: true output, dashed: model output')\n",
    "\n",
    "\n",
    "def test_binary(multiple_out=False, n_epochs=250):\n",
    "    \"\"\" Test RNN with binary outputs. \"\"\"\n",
    "    n_hidden = 10\n",
    "    n_in = 5\n",
    "    if multiple_out:\n",
    "        n_out = 2\n",
    "    else:\n",
    "        n_out = 1\n",
    "    n_steps = 10\n",
    "    n_seq = 100\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # simple lag test\n",
    "    seq = np.random.randn(n_seq, n_steps, n_in)\n",
    "    targets = np.zeros((n_seq, n_steps, n_out))\n",
    "\n",
    "    # whether lag 1 (dim 3) is greater than lag 2 (dim 0)\n",
    "    targets[:, 2:, 0] = np.cast[np.int](seq[:, 1:-1, 3] > seq[:, :-2, 0])\n",
    "\n",
    "    if multiple_out:\n",
    "        # whether product of lag 1 (dim 4) and lag 1 (dim 2)\n",
    "        # is less than lag 2 (dim 0)\n",
    "        targets[:, 2:, 1] = np.cast[np.int](\n",
    "            (seq[:, 1:-1, 4] * seq[:, 1:-1, 2]) > seq[:, :-2, 0])\n",
    "\n",
    "    model = MetaRNN(n_in=n_in, n_hidden=n_hidden, n_out=n_out,\n",
    "                    learning_rate=0.001, learning_rate_decay=0.999,\n",
    "                    n_epochs=n_epochs, activation='tanh', output_type='binary')\n",
    "\n",
    "    model.fit(seq, targets, validation_frequency=1000)\n",
    "\n",
    "    seqs = xrange(10)\n",
    "\n",
    "    plt.close('all')\n",
    "    for seq_num in seqs:\n",
    "        fig = plt.figure()\n",
    "        ax1 = plt.subplot(211)\n",
    "        plt.plot(seq[seq_num])\n",
    "        ax1.set_title('input')\n",
    "        ax2 = plt.subplot(212)\n",
    "        true_targets = plt.step(xrange(n_steps), targets[seq_num], marker='o')\n",
    "\n",
    "        guess = model.predict_proba(seq[seq_num])\n",
    "        guessed_targets = plt.step(xrange(n_steps), guess)\n",
    "        plt.setp(guessed_targets, linestyle='--', marker='d')\n",
    "        for i, x in enumerate(guessed_targets):\n",
    "            x.set_color(true_targets[i].get_color())\n",
    "        ax2.set_ylim((-0.1, 1.1))\n",
    "        ax2.set_title('solid: true output, dashed: model output (prob)')\n",
    "\n",
    "\n",
    "def test_softmax(n_epochs=250):\n",
    "    \"\"\" Test RNN with softmax outputs. \"\"\"\n",
    "    n_hidden = 10\n",
    "    n_in = 5\n",
    "    n_steps = 10\n",
    "    n_seq = 100\n",
    "    n_classes = 3\n",
    "    n_out = n_classes  # restricted to single softmax per time step\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # simple lag test\n",
    "    seq = np.random.randn(n_seq, n_steps, n_in)\n",
    "    targets = np.zeros((n_seq, n_steps), dtype=np.int)\n",
    "\n",
    "    thresh = 0.5\n",
    "    # if lag 1 (dim 3) is greater than lag 2 (dim 0) + thresh\n",
    "    # class 1\n",
    "    # if lag 1 (dim 3) is less than lag 2 (dim 0) - thresh\n",
    "    # class 2\n",
    "    # if lag 2(dim0) - thresh <= lag 1 (dim 3) <= lag2(dim0) + thresh\n",
    "    # class 0\n",
    "    targets[:, 2:][seq[:, 1:-1, 3] > seq[:, :-2, 0] + thresh] = 1\n",
    "    targets[:, 2:][seq[:, 1:-1, 3] < seq[:, :-2, 0] - thresh] = 2\n",
    "    #targets[:, 2:, 0] = np.cast[np.int](seq[:, 1:-1, 3] > seq[:, :-2, 0])\n",
    "\n",
    "    model = MetaRNN(n_in=n_in, n_hidden=n_hidden, n_out=n_out,\n",
    "                    learning_rate=0.001, learning_rate_decay=0.999,\n",
    "                    n_epochs=n_epochs, activation='tanh',\n",
    "                    output_type='softmax', use_symbolic_softmax=False)\n",
    "\n",
    "    model.fit(seq, targets, validation_frequency=1000)\n",
    "\n",
    "    seqs = xrange(10)\n",
    "\n",
    "    plt.close('all')\n",
    "    for seq_num in seqs:\n",
    "        fig = plt.figure()\n",
    "        ax1 = plt.subplot(211)\n",
    "        plt.plot(seq[seq_num])\n",
    "        ax1.set_title('input')\n",
    "        ax2 = plt.subplot(212)\n",
    "\n",
    "        # blue line will represent true classes\n",
    "        true_targets = plt.step(xrange(n_steps), targets[seq_num], marker='o')\n",
    "\n",
    "        # show probabilities (in b/w) output by model\n",
    "        guess = model.predict_proba(seq[seq_num])\n",
    "        guessed_probs = plt.imshow(guess.T, interpolation='nearest',\n",
    "                                   cmap='gray')\n",
    "        ax2.set_title('blue: true class, grayscale: probs assigned by model')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    t0 = time.time()\n",
    "    test_real()\n",
    "    # problem takes more epochs to solve\n",
    "    #test_binary(multiple_out=True, n_epochs=2400)\n",
    "    #test_softmax(n_epochs=250)\n",
    "    print \"Elapsed time: %f\" % (time.time() - t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
