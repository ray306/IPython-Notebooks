{
 "metadata": {
  "name": "",
  "signature": "sha256:44fdbe43b7e3da81fed5cde6296b0b66da42df8d9c64c250a6d98cfef2e25aaa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Standard scientific Python imports\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Import datasets, classifiers and performance metrics\n",
      "from sklearn import datasets, svm, metrics\n",
      "\n",
      "# The digits dataset\n",
      "digits = datasets.load_digits()\n",
      "# The data that we are interested in is made of 8x8 images of digits, let's\n",
      "# have a look at the first 3 images, stored in the `images` attribute of the\n",
      "# dataset.  If we were working from image files, we could load them using\n",
      "# pylab.imread.  Note that each image must have the same size. For these\n",
      "# images, we know which digit they represent: it is given in the 'target' of\n",
      "# the dataset.\n",
      "images_and_labels = list(zip(digits.images, digits.target))\n",
      "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
      "    plt.subplot(2, 4, index + 1)\n",
      "    plt.axis('off')\n",
      "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
      "    plt.title('Training: %i' % label)\n",
      "plt.show()\n",
      "# To apply a classifier on this data, we need to flatten the image, to\n",
      "# turn the data in a (samples, feature) matrix:\n",
      "import numpy as np\n",
      "n_samples = len(digits.images)\n",
      "data = digits.images.reshape((n_samples, -1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy as np\n",
      "\n",
      "# our sigmoid function, tanh is a little nicer than the standard 1/(1+e^-x)\n",
      "def sigmoid(x):\n",
      "    return math.tanh(x)\n",
      "\n",
      "# derivative of our sigmoid function, in terms of the output (i.e. y)\n",
      "def dsigmoid(y):\n",
      "    return 1.0 - y**2\n",
      "\n",
      "class NN:\n",
      "    def __init__(self, ni, nh, no):\n",
      "        \"\"\"NN constructor.\n",
      "        ni, nh, no are the number of input, hidden and output nodes.\n",
      "        \"\"\"\n",
      "        \n",
      "        #Number of input, hidden and output nodes.\n",
      "        self.ni = ni  + 1 # +1 for bias node\n",
      "        self.nh = nh  + 1 # +1 for bias node\n",
      "        self.no = no\n",
      "\n",
      "        # activations for nodes\n",
      "        self.ai = np.ones(self.ni)\n",
      "        self.ah = np.ones(self.nh)\n",
      "        self.ao = np.ones(self.no)\n",
      "        \n",
      "        # create weights, set them to random vaules\n",
      "        self.wi = np.random.rand(self.ni, self.nh)*2-1\n",
      "        self.wo = np.random.rand(self.nh, self.no)*2-1\n",
      "\n",
      "        # last change in weights for momentum   \n",
      "        self.ci = np.zeros([self.ni, self.nh])\n",
      "        self.co = np.zeros([self.nh, self.no])\n",
      "        \n",
      "    def update(self, inputs):\n",
      "        if len(inputs) != self.ni-1:\n",
      "            raise ValueError, 'wrong number of inputs'\n",
      "\n",
      "        # input activations\n",
      "        self.ai[:self.ni-1] = inputs\n",
      "\n",
      "        # hidden activations\n",
      "        for j in range(self.nh - 1):\n",
      "            total = sum(self.ai * self.wi[:,j])\n",
      "            self.ah[j] = sigmoid(total)\n",
      "\n",
      "        # output activations\n",
      "        for k in range(self.no):\n",
      "            total = sum(self.ah * self.wo[:,k])\n",
      "            self.ao[k] = sigmoid(total)\n",
      "\n",
      "        return self.ao[:]\n",
      "    \n",
      "    def backPropagate(self, targets, N, M):\n",
      "        if len(targets) != self.no:\n",
      "            raise ValueError, 'wrong number of target values'\n",
      "\n",
      "        # calculate error terms for output\n",
      "        output_deltas = np.zeros(self.no)\n",
      "        for k in range(self.no):\n",
      "            output_deltas[k] = dsigmoid(self.ao[k]) * (targets[k] - self.ao[k])\n",
      "\n",
      "        # calculate error terms for hidden\n",
      "        hidden_deltas = np.zeros(self.nh)\n",
      "        for j in range(self.nh):\n",
      "            error = sum(output_deltas*self.wo[j])\n",
      "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
      "\n",
      "        # update output weights\n",
      "        for j in range(self.nh):\n",
      "            self.wo[j] += N*output_deltas*self.ah[j] + M*self.co[j]\n",
      "            self.co[j] = output_deltas*self.ah[j]\n",
      "\n",
      "        # update input weights\n",
      "        for i in range(self.ni):\n",
      "            self.wi[i] += N*hidden_deltas*self.ai[i] + M*self.ci[i]\n",
      "            self.ci[i] = hidden_deltas*self.ai[i]\n",
      "\n",
      "        # calculate error\n",
      "        error = sum(0.5*((targets-self.ao)**2))\n",
      "        return error\n",
      "    \n",
      "    def test(self, patterns, verbose = False):\n",
      "        tmp = []\n",
      "        for p in patterns:\n",
      "            if verbose:\n",
      "                print p[0], '->', self.update(p[0])\n",
      "            tmp.append(self.update(p[0]))\n",
      "\n",
      "        return tmp\n",
      "\n",
      "        \n",
      "    def weights(self):\n",
      "        print 'Input weights:'\n",
      "        for i in range(self.ni):\n",
      "            print self.wi[i]\n",
      "        print\n",
      "        print 'Output weights:'\n",
      "        for j in range(self.nh):\n",
      "            print self.wo[j]\n",
      "\n",
      "    def train(self, patterns, iterations=1000, N=0.5, M=0.1, verbose = False):\n",
      "        \"\"\"Train the neural network.  \n",
      "        \n",
      "        N is the learning rate.\n",
      "        M is the momentum factor.\n",
      "        \"\"\"\n",
      "        for i in xrange(iterations):\n",
      "            error = 0.0\n",
      "            for p in patterns:\n",
      "                self.update(p[0])\n",
      "                tmp = self.backPropagate(p[1], N, M)\n",
      "                error += tmp\n",
      "                \n",
      "            if i % 5 == 0:\n",
      "                print 'error %-14f' % error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat = [\n",
      "        [[0,0,0], [0]],\n",
      "        [[0,1,0], [1]],\n",
      "        [[1,1,0], [1]],\n",
      "        [[1,1,1], [0]],\n",
      "        [[0,0,1], [1]],\n",
      "        [[1,0,0], [1]],\n",
      "        [[1,0,1], [1]],\n",
      "        [[0,1,1], [1]]\n",
      "    ]\n",
      "pat2 = [\n",
      "        [[1,0,1], [1]],\n",
      "        [[0,1,1], [1]]\n",
      "    ]\n",
      "\n",
      "# create a network with two input, two hidden, and one output nodes\n",
      "n = NN(3, 2, 1)\n",
      "\n",
      "# train it with some patterns then test it.\n",
      "n.train(pat, 1000, 0.5, 0.2)\n",
      "n.test(pat, verbose = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "error 0.908240      \n",
        "error 0.824603      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.785160      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.523825      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.474448      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.034192      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.064581      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.069059      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.025607      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 0.038612      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -> [-0.06953918]\n",
        "[0, 1, 0] -> [ 0.99691163]\n",
        "[1, 1, 0] -> [ 0.96978892]\n",
        "[1, 1, 1] -> [-0.13131818]\n",
        "[0, 0, 1] -> [ 0.97916023]\n",
        "[1, 0, 0] -> [ 0.9801555]\n",
        "[1, 0, 1] -> [ 0.99747496]\n",
        "[0, 1, 1] -> [ 0.97117168]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[array([ 0.97117168]),\n",
        " array([ 0.97117168]),\n",
        " array([ 0.97117168]),\n",
        " array([ 0.97117168]),\n",
        " array([ 0.97117168]),\n",
        " array([ 0.97117168]),\n",
        " array([ 0.97117168]),\n",
        " array([ 0.97117168])]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping = {0:[0,0,0,0,0,0,0,0,0,1],\n",
      "           1:[0,0,0,0,0,0,0,0,1,0],\n",
      "           2:[0,0,0,0,0,0,0,1,0,0],\n",
      "           3:[0,0,0,0,0,0,1,0,0,0],\n",
      "           4:[0,0,0,0,0,1,0,0,0,0],\n",
      "           5:[0,0,0,0,1,0,0,0,0,0],\n",
      "           6:[0,0,0,1,0,0,0,0,0,0],\n",
      "           7:[0,0,1,0,0,0,0,0,0,0],\n",
      "           8:[0,1,0,0,0,0,0,0,0,0],\n",
      "           9:[1,0,0,0,0,0,0,0,0,0]}\n",
      "bidata = np.int8(data>6)\n",
      "pat = [[bidata[n], mapping[digits.target[n]]] for n in range(1000)]\n",
      "\n",
      "# create a network with two input, two hidden, and one output nodes\n",
      "n = NN(64,16,10)\n",
      "\n",
      "# train it with some patterns then test it.\n",
      "n.train(pat, 400, 0.5, 0.2)\n",
      "n.test(pat, verbose = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "error 4751.872259   \n",
        "error 4518.372167   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.966142   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4577.881696   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4494.591436   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4770.827970   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4490.708798   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4501.798562   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.970217   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.998028   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.997380   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.995793   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.986376   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.919741   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.994664   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.966676   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.785339   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.922341   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.995151   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.986950   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.994968   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.989959   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.582228   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.997718   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.996969   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.995257   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.986761   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.995224   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.987789   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.992424   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.980222   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.998540   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.997964   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "error 4499.996565   "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-47-85a4d4f20944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# train it with some patterns then test it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-18-2a08c62c0aff>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, patterns, iterations, N, M, verbose)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m                 \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackPropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-18-2a08c62c0aff>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# hidden activations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnh\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mai\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mah\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
      "model = BernoulliRBM(n_components=2)\n",
      "model.fit(X)\n",
      "classifier.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=2, n_iter=10,\n",
        "       random_state=None, verbose=False)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "print(__doc__)\n",
      "\n",
      "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
      "# License: BSD\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from scipy.ndimage import convolve\n",
      "from sklearn import linear_model, datasets, metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Setting up\n",
      "\n",
      "def nudge_dataset(X, Y):\n",
      "    \"\"\"\n",
      "    This produces a dataset 5 times bigger than the original one,\n",
      "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
      "    \"\"\"\n",
      "    direction_vectors = [\n",
      "        [[0, 1, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [1, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 1, 0]]]\n",
      "\n",
      "    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',\n",
      "                                  weights=w).ravel()\n",
      "    X = np.concatenate([X] +\n",
      "                       [np.apply_along_axis(shift, 1, X, vector)\n",
      "                        for vector in direction_vectors])\n",
      "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
      "    return X, Y\n",
      "\n",
      "# Load Data\n",
      "digits = datasets.load_digits()\n",
      "X = np.asarray(digits.data, 'float32')\n",
      "X, Y = nudge_dataset(X, digits.target)\n",
      "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
      "\n",
      "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)\n",
      "\n",
      "# Models we will use\n",
      "logistic = linear_model.LogisticRegression()\n",
      "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
      "\n",
      "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
      "\n",
      "###############################################################################\n",
      "# Training\n",
      "\n",
      "# Hyper-parameters. These were set by cross-validation,\n",
      "# using a GridSearchCV. Here we are not performing cross-validation to\n",
      "# save time.\n",
      "rbm.learning_rate = 0.06\n",
      "rbm.n_iter = 20\n",
      "# More components tend to give better prediction performance, but larger\n",
      "# fitting time\n",
      "rbm.n_components = 100\n",
      "logistic.C = 6000.0\n",
      "\n",
      "# Training RBM-Logistic Pipeline\n",
      "classifier.fit(X_train, Y_train)\n",
      "\n",
      "# Training Logistic regression\n",
      "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
      "logistic_classifier.fit(X_train, Y_train)\n",
      "\n",
      "###############################################################################\n",
      "# Evaluation\n",
      "\n",
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        Y_test,\n",
      "        classifier.predict(X_test))))\n",
      "\n",
      "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        Y_test,\n",
      "        logistic_classifier.predict(X_test))))\n",
      "\n",
      "###############################################################################\n",
      "# Plotting\n",
      "\n",
      "plt.figure(figsize=(4.2, 4))\n",
      "for i, comp in enumerate(rbm.components_):\n",
      "    plt.subplot(10, 10, i + 1)\n",
      "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r,\n",
      "               interpolation='nearest')\n",
      "    plt.xticks(())\n",
      "    plt.yticks(())\n",
      "plt.suptitle('100 components extracted by RBM', fontsize=16)\n",
      "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n",
        "Iteration 0, pseudo-likelihood = -28.84, time = 1.78s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 1, pseudo-likelihood = -25.92, time = 1.44s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 2, pseudo-likelihood = -24.82, time = 1.93s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 3, pseudo-likelihood = -23.71, time = 1.30s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 4, pseudo-likelihood = -23.03, time = 0.79s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 5, pseudo-likelihood = -22.44, time = 0.71s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 6, pseudo-likelihood = -21.91, time = 0.67s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 7, pseudo-likelihood = -21.66, time = 0.69s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 8, pseudo-likelihood = -21.39, time = 0.71s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 9, pseudo-likelihood = -21.07, time = 0.70s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 10, pseudo-likelihood = -20.85, time = 1.05s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 11, pseudo-likelihood = -20.74, time = 0.75s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 12, pseudo-likelihood = -20.57, time = 0.72s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 13, pseudo-likelihood = -20.44, time = 0.98s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 14, pseudo-likelihood = -20.29, time = 0.87s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 15, pseudo-likelihood = -20.20, time = 0.85s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 16, pseudo-likelihood = -19.98, time = 0.71s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 17, pseudo-likelihood = -19.75, time = 0.80s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 18, pseudo-likelihood = -19.78, time = 0.73s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 19, pseudo-likelihood = -19.67, time = 0.71s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic regression using RBM features:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.99      0.99      0.99       174\n",
        "          1       0.92      0.95      0.93       184\n",
        "          2       0.95      0.98      0.97       166\n",
        "          3       0.97      0.91      0.94       194\n",
        "          4       0.97      0.95      0.96       186\n",
        "          5       0.93      0.93      0.93       181\n",
        "          6       0.98      0.97      0.97       207\n",
        "          7       0.95      1.00      0.97       154\n",
        "          8       0.90      0.88      0.89       182\n",
        "          9       0.91      0.93      0.92       169\n",
        "\n",
        "avg / total       0.95      0.95      0.95      1797\n",
        "\n",
        "\n",
        "Logistic regression using raw pixel features:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.85      0.94      0.89       174\n",
        "          1       0.57      0.55      0.56       184\n",
        "          2       0.72      0.85      0.78       166\n",
        "          3       0.76      0.74      0.75       194\n",
        "          4       0.85      0.82      0.84       186\n",
        "          5       0.74      0.75      0.75       181\n",
        "          6       0.93      0.88      0.91       207\n",
        "          7       0.86      0.90      0.88       154\n",
        "          8       0.68      0.55      0.61       182\n",
        "          9       0.71      0.74      0.72       169\n",
        "\n",
        "avg / total       0.77      0.77      0.77      1797\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}